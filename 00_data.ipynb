{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Data notebook",
   "metadata": {
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "cell_id": "44104547-023c-4ddf-bd9f-397376a16c28",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "cell_id": "893a37b5-ed1f-41f1-97ba-339a15a6c015",
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Setup",
   "metadata": {
    "cell_id": "fa0d01f06978475b8b3649e044988f56",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "49948d0c95f74d939197fc7908857d7b",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a5f683e2",
    "execution_start": 1668427493170,
    "execution_millis": 12095,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 730.6875,
    "deepnote_output_heights": [
     null,
     20.1875
    ]
   },
   "source": "!python -m pip install tqdm requests nltk\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('omw-1.4')",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: tqdm in /shared-libs/python3.9/py/lib/python3.9/site-packages (4.64.1)\nRequirement already satisfied: requests in /shared-libs/python3.9/py/lib/python3.9/site-packages (2.28.1)\nRequirement already satisfied: nltk in /shared-libs/python3.9/py/lib/python3.9/site-packages (3.7)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests) (2.1.1)\nRequirement already satisfied: click in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (8.1.3)\nRequirement already satisfied: joblib in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (2022.9.13)\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /root/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "True"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "5831d688d4ec40f8a157536ddfb1ce81",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a600ca46",
    "execution_start": 1668427504870,
    "execution_millis": 947,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 400
   },
   "source": "from IPython.display import display\nimport pandas as pd\nimport requests\nimport re\nfrom urllib.request import urlopen\nimport csv\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n#from fa2 import ForceAtlas2\nfrom scipy import stats\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nimport io\nfrom tqdm import tqdm\nfrom heapq import nlargest \nimport seaborn as sns\nsns.set()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Getting the data",
   "metadata": {
    "cell_id": "74ceb02bffce4e0896ea411e21f325f2",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "markdown",
   "source": "Based on https://www.dr.dk/nyheder/politik/folketingsvalg/valgte a list of the top 3 politicians by vote from each party with at least 5 mandates as of the 2022 danish election is created. \n\nData is collected using the <font color=\"red\"> TODO </font> twitter API. \n\nAs the twitter API needs the twitter user id to collect tweets, the twitter user ids are manually collected using the [\"Find Twitter ID\"](https://www.codeofaninja.com/tools/find-twitter-id/) by [CodeOfaNinja](https://www.codeofaninja.com/).\n\nThe resulting politicians and their twitter ids are seen in the dataframe below.\n\nWe observe that we have 12 different parties and 36 politicians in total.",
   "metadata": {
    "cell_id": "97f758fcb5e24b53a320965b73ba3434",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 220.34375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "f313b9778e334d7e90a647085aeadc8a",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e781c1d6",
    "execution_start": 1668427505838,
    "execution_millis": 81,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 757
   },
   "source": "from Data.twitter_ids import twitter_ids\n\ntwitter_id_df = pd.DataFrame(columns=['name', \"party\", 'twitter_id'])\ni = 0\nfor party in twitter_ids:\n    for person in twitter_ids[party]:\n        twitter_id_df.loc[i, :] = [person, party, twitter_ids[party][person]]\n        i += 1\n\ndisplay(twitter_id_df)",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "application/vnd.deepnote.dataframe.v3+json": {
       "column_count": 3,
       "row_count": 36,
       "columns": [
        {
         "name": "name",
         "dtype": "object",
         "stats": {
          "unique_count": 36,
          "nan_count": 0,
          "categories": [
           {
            "name": "magnus_heunicke",
            "count": 1
           },
           {
            "name": "nicolai_wammen",
            "count": 1
           },
           {
            "name": "34 others",
            "count": 34
           }
          ]
         }
        },
        {
         "name": "party",
         "dtype": "object",
         "stats": {
          "unique_count": 12,
          "nan_count": 0,
          "categories": [
           {
            "name": "socialdemokratiet",
            "count": 3
           },
           {
            "name": "venstre",
            "count": 3
           },
           {
            "name": "10 others",
            "count": 30
           }
          ]
         }
        },
        {
         "name": "twitter_id",
         "dtype": "object",
         "stats": {
          "unique_count": 36,
          "nan_count": 0,
          "categories": [
           {
            "name": "22695562",
            "count": 1
           },
           {
            "name": "2803948786",
            "count": 1
           },
           {
            "name": "34 others",
            "count": 34
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows": [
        {
         "name": "magnus_heunicke",
         "party": "socialdemokratiet",
         "twitter_id": "22695562",
         "_deepnote_index_column": "0"
        },
        {
         "name": "nicolai_wammen",
         "party": "socialdemokratiet",
         "twitter_id": "2803948786",
         "_deepnote_index_column": "1"
        },
        {
         "name": "mattias_tesfaye",
         "party": "socialdemokratiet",
         "twitter_id": "546254893",
         "_deepnote_index_column": "2"
        },
        {
         "name": "jakob_ellemann",
         "party": "venstre",
         "twitter_id": "155584627",
         "_deepnote_index_column": "3"
        },
        {
         "name": "soren_gade",
         "party": "venstre",
         "twitter_id": "975064362359623680",
         "_deepnote_index_column": "4"
        },
        {
         "name": "sophie_lohde",
         "party": "venstre",
         "twitter_id": "44611200",
         "_deepnote_index_column": "5"
        },
        {
         "name": "lars_lokke",
         "party": "moderaterne",
         "twitter_id": "26201346",
         "_deepnote_index_column": "6"
        },
        {
         "name": "henrik_frandsen",
         "party": "moderaterne",
         "twitter_id": "1249019841924734977",
         "_deepnote_index_column": "7"
        },
        {
         "name": "rosa_eriksen",
         "party": "moderaterne",
         "twitter_id": "1560192117858861056",
         "_deepnote_index_column": "8"
        },
        {
         "name": "jacob_mark",
         "party": "sf",
         "twitter_id": "2373406198",
         "_deepnote_index_column": "9"
        }
       ]
      },
      "text/plain": "                    name                 party           twitter_id\n0        magnus_heunicke     socialdemokratiet             22695562\n1         nicolai_wammen     socialdemokratiet           2803948786\n2        mattias_tesfaye     socialdemokratiet            546254893\n3         jakob_ellemann               venstre            155584627\n4             soren_gade               venstre   975064362359623680\n5           sophie_lohde               venstre             44611200\n6             lars_lokke           moderaterne             26201346\n7        henrik_frandsen           moderaterne  1249019841924734977\n8           rosa_eriksen           moderaterne  1560192117858861056\n9             jacob_mark                    sf           2373406198\n10              pia_dyhr                    sf             65025162\n11      kirsten_andersen                    sf            235646319\n12      dennis_flydtkjær  danmarksdemokraterne            531595033\n13         peter_skaarup  danmarksdemokraterne           3144074691\n14        soren_espersen  danmarksdemokraterne           2444718215\n15       alex_vanopslagh      liberal_alliance           1531564633\n16            ole_olesen      liberal_alliance           2222188479\n17     solbjorg_jakobsen      liberal_alliance  1548641745264644099\n18            soren_pape          konservative           2712091824\n19      mette_abildgaard          konservative             37877392\n20         rasmus_jarlov          konservative           1225930531\n21        pelle_dragsted          enhedslisten            119879630\n22         mai_villadsen          enhedslisten           4724782641\n23             rosa_lund          enhedslisten            736979161\n24      martin_lidegaard              radikale           1070745218\n25           samira_nawa              radikale             92107029\n26        katrine_robsoe              radikale           2491403660\n27      pernille_vermund        nye_borgerlige             24687777\n28        lars_mathiesen        nye_borgerlige            980721900\n29          kim_andersen        nye_borgerlige   783935815600799744\n30  franciska_rosenkilde          alternativet   777113466205274112\n31     christina_olumeko          alternativet  1324801335372488707\n32          torsten_gejl          alternativet           2806864609\n33  morten_messerschmidt      dansk_folkeparti            509288627\n34        pia_kjarsgaard      dansk_folkeparti  1054640354690039809\n35           peter_kofod      dansk_folkeparti           1613378210",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>party</th>\n      <th>twitter_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magnus_heunicke</td>\n      <td>socialdemokratiet</td>\n      <td>22695562</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>nicolai_wammen</td>\n      <td>socialdemokratiet</td>\n      <td>2803948786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mattias_tesfaye</td>\n      <td>socialdemokratiet</td>\n      <td>546254893</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>jakob_ellemann</td>\n      <td>venstre</td>\n      <td>155584627</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>soren_gade</td>\n      <td>venstre</td>\n      <td>975064362359623680</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>sophie_lohde</td>\n      <td>venstre</td>\n      <td>44611200</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>lars_lokke</td>\n      <td>moderaterne</td>\n      <td>26201346</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>henrik_frandsen</td>\n      <td>moderaterne</td>\n      <td>1249019841924734977</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>rosa_eriksen</td>\n      <td>moderaterne</td>\n      <td>1560192117858861056</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>jacob_mark</td>\n      <td>sf</td>\n      <td>2373406198</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>pia_dyhr</td>\n      <td>sf</td>\n      <td>65025162</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>kirsten_andersen</td>\n      <td>sf</td>\n      <td>235646319</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>dennis_flydtkjær</td>\n      <td>danmarksdemokraterne</td>\n      <td>531595033</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>peter_skaarup</td>\n      <td>danmarksdemokraterne</td>\n      <td>3144074691</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>soren_espersen</td>\n      <td>danmarksdemokraterne</td>\n      <td>2444718215</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>alex_vanopslagh</td>\n      <td>liberal_alliance</td>\n      <td>1531564633</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ole_olesen</td>\n      <td>liberal_alliance</td>\n      <td>2222188479</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>solbjorg_jakobsen</td>\n      <td>liberal_alliance</td>\n      <td>1548641745264644099</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>soren_pape</td>\n      <td>konservative</td>\n      <td>2712091824</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>mette_abildgaard</td>\n      <td>konservative</td>\n      <td>37877392</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>rasmus_jarlov</td>\n      <td>konservative</td>\n      <td>1225930531</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>pelle_dragsted</td>\n      <td>enhedslisten</td>\n      <td>119879630</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>mai_villadsen</td>\n      <td>enhedslisten</td>\n      <td>4724782641</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>rosa_lund</td>\n      <td>enhedslisten</td>\n      <td>736979161</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>martin_lidegaard</td>\n      <td>radikale</td>\n      <td>1070745218</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>samira_nawa</td>\n      <td>radikale</td>\n      <td>92107029</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>katrine_robsoe</td>\n      <td>radikale</td>\n      <td>2491403660</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>pernille_vermund</td>\n      <td>nye_borgerlige</td>\n      <td>24687777</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>lars_mathiesen</td>\n      <td>nye_borgerlige</td>\n      <td>980721900</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>kim_andersen</td>\n      <td>nye_borgerlige</td>\n      <td>783935815600799744</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>franciska_rosenkilde</td>\n      <td>alternativet</td>\n      <td>777113466205274112</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>christina_olumeko</td>\n      <td>alternativet</td>\n      <td>1324801335372488707</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>torsten_gejl</td>\n      <td>alternativet</td>\n      <td>2806864609</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>morten_messerschmidt</td>\n      <td>dansk_folkeparti</td>\n      <td>509288627</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>pia_kjarsgaard</td>\n      <td>dansk_folkeparti</td>\n      <td>1054640354690039809</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>peter_kofod</td>\n      <td>dansk_folkeparti</td>\n      <td>1613378210</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The dataset is then created with the Twitter API using these ids and the code used for this is collected in the file `data_request.ipynb`. <font color=\"red\"> TODO </font> collect data retrieving code in py file and explain it here.\n\nThis results in multiple csv files for each politician looking like this:",
   "metadata": {
    "cell_id": "f8c83df0924d4964ba59c9c47ce1283f",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 111.171875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "5bb1844a4aca4f1faa8dafa0a2ec5af8",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "992d51db",
    "execution_start": 1668427505916,
    "execution_millis": 54,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 474.5625,
    "deepnote_output_heights": [
     null,
     176
    ]
   },
   "source": "print(\"Example of data frame: \")\nexample_df = pd.read_csv(\"Data/alternativet/christina_olumeko_0.csv\", index_col=0)\ndisplay(example_df.head())\n\nprint(\"\\033[1mExample of tweet: \\033[0m\")\nprint(example_df.loc[0, \"text\"])",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Example of data frame: \n",
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "    edit_history_tweet_ids                   id  \\\n0  ['1566066637933088769']  1566066637933088769   \n1  ['1566055972031922176']  1566055972031922176   \n2  ['1565978593318129665']  1565978593318129665   \n3  ['1565956735612985347']  1565956735612985347   \n4  ['1565947952501334018']  1565947952501334018   \n\n                                                text  \n0  Rigtig ærgerligt, at Socialdemokratiet dropper...  \n1  “Kommissionen for den glemte kvindekamp” under...  \n2  @Mhvid @SophieHAndersen Ja og særligt når komm...  \n3  Grineren video fra ⁦@Vejdirektoratet⁩. Lad os ...  \n4  @AFreltoft @politiken Dejligt at Københavns go...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>edit_history_tweet_ids</th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['1566066637933088769']</td>\n      <td>1566066637933088769</td>\n      <td>Rigtig ærgerligt, at Socialdemokratiet dropper...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['1566055972031922176']</td>\n      <td>1566055972031922176</td>\n      <td>“Kommissionen for den glemte kvindekamp” under...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['1565978593318129665']</td>\n      <td>1565978593318129665</td>\n      <td>@Mhvid @SophieHAndersen Ja og særligt når komm...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['1565956735612985347']</td>\n      <td>1565956735612985347</td>\n      <td>Grineren video fra ⁦@Vejdirektoratet⁩. Lad os ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['1565947952501334018']</td>\n      <td>1565947952501334018</td>\n      <td>@AFreltoft @politiken Dejligt at Københavns go...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": "\u001b[1mExample of tweet: \u001b[0m\nRigtig ærgerligt, at Socialdemokratiet dropper at arbejde for mindre gadeparkering i København🚗Det optager nemlig meget plads, og er samtidig nødvendigt for at nå Københavns klimamål. Alternativet arbejder videre 🌱 #dkgreen https://t.co/lUB0dMk5ud\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Data cleaning",
   "metadata": {
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "cell_id": "138af563-7ae3-4d6e-bfdc-1e05e2c5e0f4",
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "markdown",
   "source": "As we are only interested in the text of each tweet, we will collect the text for each politician as a list of strings (tweets) and add it as a new column to the data. However, we would like to clean the text a bit before doing this, for this purpose we do the following:\n\n- only keep words and numbers, i.e. no emojis\n- remove punctuation, stopwords and urls\n- make all words lowercase\n\n<font color=\"red\"> Maybe we can use mrjob to do this? </font>",
   "metadata": {
    "cell_id": "d93a9f1f559d4d538a3a3ccc0593f65d",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 198.34375
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Single tweet",
   "metadata": {
    "cell_id": "f47d02ec2cde407fa53531ee06e638c8",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "99b271dca9c44e838984c018272db114",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "50b77ce6",
    "execution_start": 1668427505978,
    "execution_millis": 2713,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 482.125
   },
   "source": "t = example_df.loc[0, \"text\"]\n\nwnl = nltk.WordNetLemmatizer() \nSTOPWORDS = nltk.corpus.stopwords.words('danish') #+ [\"http\"]\n\ndef clean_tweet(tweet):\n    tokensraw = word_tokenize(tweet) #get tokens \n    tokens = [word.lower() for word in tokensraw if word.isalnum()] #only get words and numbers\n    tokens = [wnl.lemmatize(t) for t in tokens] #lemmatize tokens\n    tokens = [w for w in tokens if w.lower() not in STOPWORDS] #remove stopwords\n    return tokens\n\nprint(\"Original tweet: \\n\", t)\nprint(\"\\n\")\nprint(\"Clean tweet: \\n\" + \" \".join(clean_tweet(t)))\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Original tweet: \n Rigtig ærgerligt, at Socialdemokratiet dropper at arbejde for mindre gadeparkering i København🚗Det optager nemlig meget plads, og er samtidig nødvendigt for at nå Københavns klimamål. Alternativet arbejder videre 🌱 #dkgreen https://t.co/lUB0dMk5ud\n\n\nClean tweet: \nrigtig ærgerligt socialdemokratiet dropper arbejde mindre gadeparkering optager nemlig plads samtidig nødvendigt nå københavns klimamål alternativet arbejder videre dkgreen http\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "cell_id": "8391a2ad-3615-43bd-9802-66904eac9f4e",
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Multiple tweets",
   "metadata": {
    "cell_id": "b2263ae7c0f84813b6e4b54d87af7301",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4fd71cf699bc45ce8a5c41b616b90659",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cdc5f1c",
    "execution_start": 1668427508107,
    "execution_millis": 661,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 165.1875
   },
   "source": "import glob\n# All files and directories ending with .txt and that don't begin with a dot:\nprint(glob.glob(\"Data/*\")) \n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "['Data/__pycache__', 'Data/twitter_ids.py', 'Data/dansk_folkeparti', 'Data/enhedslisten', 'Data/test_payload.csv', 'Data/sf', 'Data/alternativet', 'Data/venstre', 'Data/radikale', 'Data/danmarksdemokraterne', 'Data/socialdemokratiet', 'Data/konservative', 'Data/nye_borgerlige', 'Data/backup_plan_tweets.csv', 'Data/moderaterne', 'Data/liberal_alliance']\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "ae97d0ebd31b4a70b727546d9bd0d9b6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2cef9e2a",
    "execution_start": 1668427508120,
    "execution_millis": 9,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 292
   },
   "source": "#cleaning each twitter period in the party folder:\n\nsubfolders = [ f.path for f in os.scandir(\"Data/\") if f.is_dir() ][1:]\nfor folder in subfolders:\n    files = glob.glob(folder + \"*.csv\")\n    tokens_list = []\n    for partimedlem in files:\n        for i in range(partimedlem.shape[0]):\n            raw = partimedlem.text.iloc[i]\n            tokensraw = word_tokenize(raw) #get tokens from wikipage\n            tokens = [word.lower() for word in tokensraw if word.isalnum()] #only get words and numbers\n            tokens = [wnl.lemmatize(t) for t in tokens] #lemmatize tokens\n            marvel_tokens += tokens",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "cb0b6fd3b5754760a979f814f72018f9",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c5d206a4",
    "execution_start": 1668427509210,
    "execution_millis": 835,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 283.1875
   },
   "source": "wnl = nltk.WordNetLemmatizer() \n\ntokens_list = []\nfor i in range(data.shape[0]):\n    raw = data[\"text\"].iloc[i]\n    tokensraw = word_tokenize(raw) #get tokens \n    tokens = [word.lower() for word in tokensraw if word.isalnum()] #only get words and numbers\n    tokens = [wnl.lemmatize(t) for t in tokens] #lemmatize tokens\n    tokens_list += tokens",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m wnl \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mWordNetLemmatizer() \n\u001b[1;32m      3\u001b[0m tokens_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      5\u001b[0m     raw \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[1;32m      6\u001b[0m     tokensraw \u001b[38;5;241m=\u001b[39m word_tokenize(raw) \u001b[38;5;66;03m#get tokens \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "7130c8b2515845bc93ec19af29e2e125",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1668427515396,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 76
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "b352469b0d0847d79eeeec51550a04a7",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1668427515510,
    "execution_millis": 2,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 76
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "7f9a9852ffc34170b456d3520d3a81d1",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 61
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=30797f9c-952e-45b4-98d4-31c9ac73ae78' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  },
  "deepnote_notebook_id": "c6688788-fae5-44cc-a7a4-3ca4227f9d65",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}