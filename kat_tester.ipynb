{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "cell_id": "b9d670f9-28bf-4981-8f9e-cf22056d423f",
    "deepnote_cell_height": 436,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3792,
    "execution_start": 1668958920397,
    "source_hash": "522fcc3f"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import display\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# import re\n",
    "# from urllib.request import urlopen\n",
    "# import csv\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# #from fa2 import ForceAtlas2\n",
    "# from scipy import stats\n",
    "# import nltk\n",
    "# from nltk import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# import io\n",
    "# from tqdm import tqdm\n",
    "# from heapq import nlargest \n",
    "# import seaborn as sns\n",
    "# import simplemma\n",
    "\n",
    "# sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data med mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Requirement already satisfied: spacy in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 1)) (3.4.3)\n",
      "Requirement already satisfied: mrjob==0.7.4 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 2)) (0.7.4)\n",
      "Requirement already satisfied: simplemma in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 4)) (4.64.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 5)) (3.7)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 6)) (1.8.2.2)\n",
      "Requirement already satisfied: sklearn in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 7)) (0.0.post1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from mrjob==0.7.4->-r requirements.txt (line 2)) (6.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (2022.10.31)\n",
      "Requirement already satisfied: joblib in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (8.1.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (2.28.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (1.22.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (1.10.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (2.4.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (8.1.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (1.0.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (0.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (61.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from tqdm->-r requirements.txt (line 4)) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from packaging>=20.0->spacy->-r requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from pathy>=0.3.5->spacy->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 1)) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 1)) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 1)) (2022.5.18.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 1)) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 1)) (0.7.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from wordcloud->-r requirements.txt (line 6)) (9.1.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from wordcloud->-r requirements.txt (line 6)) (3.5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from jinja2->spacy->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (4.33.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (1.4.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud->-r requirements.txt (line 6)) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\bayka\\Anaconda3\\envs\\katrine_personal_env\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>twitter_id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>magnus_heunicke</td>\n",
       "      <td>socialdemokratiet</td>\n",
       "      <td>22695562</td>\n",
       "      <td>[afsætter året styrke hjælpen børn pårørende a...</td>\n",
       "      <td>[afsætter, året, styrke, hjælpen, børn, pårøre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nicolai_wammen</td>\n",
       "      <td>socialdemokratiet</td>\n",
       "      <td>2803948786</td>\n",
       "      <td>[dage siden sagde nyt ejendomsvurderingssystem...</td>\n",
       "      <td>[dage, siden, sagde, nyt, ejendomsvurderingssy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mattias_tesfaye</td>\n",
       "      <td>socialdemokratiet</td>\n",
       "      <td>546254893</td>\n",
       "      <td>[this is literally the same logic many th c am...</td>\n",
       "      <td>[this, is, literally, the, same, logic, many, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jakob_ellemann</td>\n",
       "      <td>venstre</td>\n",
       "      <td>155584627</td>\n",
       "      <td>[tide få fleksibel genåbning vores børn ældre ...</td>\n",
       "      <td>[tide, få, fleksibel, genåbning, vores, børn, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soren_gade</td>\n",
       "      <td>venstre</td>\n",
       "      <td>975064362359623680</td>\n",
       "      <td>[kære marianne synes burde læse lovforslaget i...</td>\n",
       "      <td>[kære, marianne, synes, burde, læse, lovforsla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sophie_lohde</td>\n",
       "      <td>venstre</td>\n",
       "      <td>44611200</td>\n",
       "      <td>[flertallet veto dermed røde partier stort set...</td>\n",
       "      <td>[flertallet, veto, dermed, røde, partier, stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lars_lokke</td>\n",
       "      <td>moderaterne</td>\n",
       "      <td>26201346</td>\n",
       "      <td>[mon ikke sjov form argumentation mangler lidt...</td>\n",
       "      <td>[mon, ikke, sjov, form, argumentation, mangler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jacob_mark</td>\n",
       "      <td>sf</td>\n",
       "      <td>2373406198</td>\n",
       "      <td>[slår fast syvtommersøm kom så godt igennem fo...</td>\n",
       "      <td>[slår, fast, syvtommersøm, kom, så, godt, igen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pia_dyhr</td>\n",
       "      <td>sf</td>\n",
       "      <td>65025162</td>\n",
       "      <td>[stemmer nok selvom synes gør godt klaus, brug...</td>\n",
       "      <td>[stemmer, nok, selvom, synes, gør, godt, klaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kirsten_andersen</td>\n",
       "      <td>sf</td>\n",
       "      <td>235646319</td>\n",
       "      <td>[arbejde få medarbejdere ser virkeligheden sun...</td>\n",
       "      <td>[arbejde, få, medarbejdere, ser, virkeligheden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dennis_flydtkjær</td>\n",
       "      <td>danmarksdemokraterne</td>\n",
       "      <td>531595033</td>\n",
       "      <td>[vel blot gældende forlig k i åbner det, europ...</td>\n",
       "      <td>[vel, blot, gældende, forlig, k, i, åbner, det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>peter_skaarup</td>\n",
       "      <td>danmarksdemokraterne</td>\n",
       "      <td>3144074691</td>\n",
       "      <td>[justitsminister åbenbart svare på ogeller sik...</td>\n",
       "      <td>[justitsminister, åbenbart, svare, på, ogeller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>soren_espersen</td>\n",
       "      <td>danmarksdemokraterne</td>\n",
       "      <td>2444718215</td>\n",
       "      <td>[godt arbejde, det undre allermest forbindelse...</td>\n",
       "      <td>[godt, arbejde, det, undre, allermest, forbind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>alex_vanopslagh</td>\n",
       "      <td>liberal_alliance</td>\n",
       "      <td>1531564633</td>\n",
       "      <td>[tror mest mennesket sætter gud prøve, mette f...</td>\n",
       "      <td>[tror, mest, mennesket, sætter, gud, prøve, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ole_olesen</td>\n",
       "      <td>liberal_alliance</td>\n",
       "      <td>2222188479</td>\n",
       "      <td>[findes ingen talemåde slå stålet så andet ste...</td>\n",
       "      <td>[findes, ingen, talemåde, slå, stålet, så, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soren_pape</td>\n",
       "      <td>konservative</td>\n",
       "      <td>2712091824</td>\n",
       "      <td>[tak mindst tak konstruktive input, dag god da...</td>\n",
       "      <td>[tak, mindst, tak, konstruktive, input, dag, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mette_abildgaard</td>\n",
       "      <td>konservative</td>\n",
       "      <td>37877392</td>\n",
       "      <td>[men kæmpe indsatsen lavere fjernvarmepriser n...</td>\n",
       "      <td>[men, kæmpe, indsatsen, lavere, fjernvarmepris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rasmus_jarlov</td>\n",
       "      <td>konservative</td>\n",
       "      <td>1225930531</td>\n",
       "      <td>[fuldstændig korrekt budskabet opslag sidste s...</td>\n",
       "      <td>[fuldstændig, korrekt, budskabet, opslag, sids...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pelle_dragsted</td>\n",
       "      <td>enhedslisten</td>\n",
       "      <td>119879630</td>\n",
       "      <td>[syriske mariam udvises gift jan venter barn l...</td>\n",
       "      <td>[syriske, mariam, udvises, gift, jan, venter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mai_villadsen</td>\n",
       "      <td>enhedslisten</td>\n",
       "      <td>4724782641</td>\n",
       "      <td>[husk sexisme seksuel chikane magt arbejde gør...</td>\n",
       "      <td>[husk, sexisme, seksuel, chikane, magt, arbejd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rosa_lund</td>\n",
       "      <td>enhedslisten</td>\n",
       "      <td>736979161</td>\n",
       "      <td>[russiske flygtninge større chance få asyl ukr...</td>\n",
       "      <td>[russiske, flygtninge, større, chance, få, asy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>martin_lidegaard</td>\n",
       "      <td>radikale</td>\n",
       "      <td>1070745218</td>\n",
       "      <td>[ja dokumentere fem år arbejdet indenfor felt ...</td>\n",
       "      <td>[ja, dokumentere, fem, år, arbejdet, indenfor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>samira_nawa</td>\n",
       "      <td>radikale</td>\n",
       "      <td>92107029</td>\n",
       "      <td>[andet vigtigt klimarådet konkluderer dag lang...</td>\n",
       "      <td>[andet, vigtigt, klimarådet, konkluderer, dag,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>katrine_robsoe</td>\n",
       "      <td>radikale</td>\n",
       "      <td>2491403660</td>\n",
       "      <td>[tak samarbejdet, godt dkpol, vores uddannelse...</td>\n",
       "      <td>[tak, samarbejdet, godt, dkpol, vores, uddanne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pernille_vermund</td>\n",
       "      <td>nye_borgerlige</td>\n",
       "      <td>24687777</td>\n",
       "      <td>[lars løkke varslede åbningstale flere udlændi...</td>\n",
       "      <td>[lars, løkke, varslede, åbningstale, flere, ud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lars_mathiesen</td>\n",
       "      <td>nye_borgerlige</td>\n",
       "      <td>980721900</td>\n",
       "      <td>[siger del svagt enhedslisten reelt står rød b...</td>\n",
       "      <td>[siger, del, svagt, enhedslisten, reelt, står,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kim_andersen</td>\n",
       "      <td>nye_borgerlige</td>\n",
       "      <td>783935815600799744</td>\n",
       "      <td>[vestlige erhvervsaktive alder stort underskud...</td>\n",
       "      <td>[vestlige, erhvervsaktive, alder, stort, under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>franciska_rosenkilde</td>\n",
       "      <td>alternativet</td>\n",
       "      <td>777113466205274112</td>\n",
       "      <td>[sjøst sidste brug lige nu støjbergs sløje kul...</td>\n",
       "      <td>[sjøst, sidste, brug, lige, nu, støjbergs, slø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>christina_olumeko</td>\n",
       "      <td>alternativet</td>\n",
       "      <td>1324801335372488707</td>\n",
       "      <td>[rigtig ærgerligt socialdemokratiet dropper ar...</td>\n",
       "      <td>[rigtig, ærgerligt, socialdemokratiet, dropper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>torsten_gejl</td>\n",
       "      <td>alternativet</td>\n",
       "      <td>2806864609</td>\n",
       "      <td>[stolte kåringen, hej randahl, ja lille parti ...</td>\n",
       "      <td>[stolte, kåringen, hej, randahl, ja, lille, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>morten_messerschmidt</td>\n",
       "      <td>dansk_folkeparti</td>\n",
       "      <td>509288627</td>\n",
       "      <td>[stort velkommen tilbage folketingsgruppen ige...</td>\n",
       "      <td>[stort, velkommen, tilbage, folketingsgruppen,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pia_kjarsgaard</td>\n",
       "      <td>dansk_folkeparti</td>\n",
       "      <td>1054640354690039809</td>\n",
       "      <td>[nye borgerlige nedlægge hver femte offentlige...</td>\n",
       "      <td>[nye, borgerlige, nedlægge, hver, femte, offen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>peter_kofod</td>\n",
       "      <td>dansk_folkeparti</td>\n",
       "      <td>1613378210</td>\n",
       "      <td>[kl slår gået galt stadig redde vort land kræv...</td>\n",
       "      <td>[kl, slår, gået, galt, stadig, redde, vort, la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                 party           twitter_id  \\\n",
       "0        magnus_heunicke     socialdemokratiet             22695562   \n",
       "1         nicolai_wammen     socialdemokratiet           2803948786   \n",
       "2        mattias_tesfaye     socialdemokratiet            546254893   \n",
       "3         jakob_ellemann               venstre            155584627   \n",
       "4             soren_gade               venstre   975064362359623680   \n",
       "5           sophie_lohde               venstre             44611200   \n",
       "6             lars_lokke           moderaterne             26201346   \n",
       "7             jacob_mark                    sf           2373406198   \n",
       "8               pia_dyhr                    sf             65025162   \n",
       "9       kirsten_andersen                    sf            235646319   \n",
       "10      dennis_flydtkjær  danmarksdemokraterne            531595033   \n",
       "11         peter_skaarup  danmarksdemokraterne           3144074691   \n",
       "12        soren_espersen  danmarksdemokraterne           2444718215   \n",
       "13       alex_vanopslagh      liberal_alliance           1531564633   \n",
       "14            ole_olesen      liberal_alliance           2222188479   \n",
       "15            soren_pape          konservative           2712091824   \n",
       "16      mette_abildgaard          konservative             37877392   \n",
       "17         rasmus_jarlov          konservative           1225930531   \n",
       "18        pelle_dragsted          enhedslisten            119879630   \n",
       "19         mai_villadsen          enhedslisten           4724782641   \n",
       "20             rosa_lund          enhedslisten            736979161   \n",
       "21      martin_lidegaard              radikale           1070745218   \n",
       "22           samira_nawa              radikale             92107029   \n",
       "23        katrine_robsoe              radikale           2491403660   \n",
       "24      pernille_vermund        nye_borgerlige             24687777   \n",
       "25        lars_mathiesen        nye_borgerlige            980721900   \n",
       "26          kim_andersen        nye_borgerlige   783935815600799744   \n",
       "27  franciska_rosenkilde          alternativet   777113466205274112   \n",
       "28     christina_olumeko          alternativet  1324801335372488707   \n",
       "29          torsten_gejl          alternativet           2806864609   \n",
       "30  morten_messerschmidt      dansk_folkeparti            509288627   \n",
       "31        pia_kjarsgaard      dansk_folkeparti  1054640354690039809   \n",
       "32           peter_kofod      dansk_folkeparti           1613378210   \n",
       "\n",
       "                                               tweets  \\\n",
       "0   [afsætter året styrke hjælpen børn pårørende a...   \n",
       "1   [dage siden sagde nyt ejendomsvurderingssystem...   \n",
       "2   [this is literally the same logic many th c am...   \n",
       "3   [tide få fleksibel genåbning vores børn ældre ...   \n",
       "4   [kære marianne synes burde læse lovforslaget i...   \n",
       "5   [flertallet veto dermed røde partier stort set...   \n",
       "6   [mon ikke sjov form argumentation mangler lidt...   \n",
       "7   [slår fast syvtommersøm kom så godt igennem fo...   \n",
       "8   [stemmer nok selvom synes gør godt klaus, brug...   \n",
       "9   [arbejde få medarbejdere ser virkeligheden sun...   \n",
       "10  [vel blot gældende forlig k i åbner det, europ...   \n",
       "11  [justitsminister åbenbart svare på ogeller sik...   \n",
       "12  [godt arbejde, det undre allermest forbindelse...   \n",
       "13  [tror mest mennesket sætter gud prøve, mette f...   \n",
       "14  [findes ingen talemåde slå stålet så andet ste...   \n",
       "15  [tak mindst tak konstruktive input, dag god da...   \n",
       "16  [men kæmpe indsatsen lavere fjernvarmepriser n...   \n",
       "17  [fuldstændig korrekt budskabet opslag sidste s...   \n",
       "18  [syriske mariam udvises gift jan venter barn l...   \n",
       "19  [husk sexisme seksuel chikane magt arbejde gør...   \n",
       "20  [russiske flygtninge større chance få asyl ukr...   \n",
       "21  [ja dokumentere fem år arbejdet indenfor felt ...   \n",
       "22  [andet vigtigt klimarådet konkluderer dag lang...   \n",
       "23  [tak samarbejdet, godt dkpol, vores uddannelse...   \n",
       "24  [lars løkke varslede åbningstale flere udlændi...   \n",
       "25  [siger del svagt enhedslisten reelt står rød b...   \n",
       "26  [vestlige erhvervsaktive alder stort underskud...   \n",
       "27  [sjøst sidste brug lige nu støjbergs sløje kul...   \n",
       "28  [rigtig ærgerligt socialdemokratiet dropper ar...   \n",
       "29  [stolte kåringen, hej randahl, ja lille parti ...   \n",
       "30  [stort velkommen tilbage folketingsgruppen ige...   \n",
       "31  [nye borgerlige nedlægge hver femte offentlige...   \n",
       "32  [kl slår gået galt stadig redde vort land kræv...   \n",
       "\n",
       "                                               tokens  \n",
       "0   [afsætter, året, styrke, hjælpen, børn, pårøre...  \n",
       "1   [dage, siden, sagde, nyt, ejendomsvurderingssy...  \n",
       "2   [this, is, literally, the, same, logic, many, ...  \n",
       "3   [tide, få, fleksibel, genåbning, vores, børn, ...  \n",
       "4   [kære, marianne, synes, burde, læse, lovforsla...  \n",
       "5   [flertallet, veto, dermed, røde, partier, stor...  \n",
       "6   [mon, ikke, sjov, form, argumentation, mangler...  \n",
       "7   [slår, fast, syvtommersøm, kom, så, godt, igen...  \n",
       "8   [stemmer, nok, selvom, synes, gør, godt, klaus...  \n",
       "9   [arbejde, få, medarbejdere, ser, virkeligheden...  \n",
       "10  [vel, blot, gældende, forlig, k, i, åbner, det...  \n",
       "11  [justitsminister, åbenbart, svare, på, ogeller...  \n",
       "12  [godt, arbejde, det, undre, allermest, forbind...  \n",
       "13  [tror, mest, mennesket, sætter, gud, prøve, me...  \n",
       "14  [findes, ingen, talemåde, slå, stålet, så, and...  \n",
       "15  [tak, mindst, tak, konstruktive, input, dag, g...  \n",
       "16  [men, kæmpe, indsatsen, lavere, fjernvarmepris...  \n",
       "17  [fuldstændig, korrekt, budskabet, opslag, sids...  \n",
       "18  [syriske, mariam, udvises, gift, jan, venter, ...  \n",
       "19  [husk, sexisme, seksuel, chikane, magt, arbejd...  \n",
       "20  [russiske, flygtninge, større, chance, få, asy...  \n",
       "21  [ja, dokumentere, fem, år, arbejdet, indenfor,...  \n",
       "22  [andet, vigtigt, klimarådet, konkluderer, dag,...  \n",
       "23  [tak, samarbejdet, godt, dkpol, vores, uddanne...  \n",
       "24  [lars, løkke, varslede, åbningstale, flere, ud...  \n",
       "25  [siger, del, svagt, enhedslisten, reelt, står,...  \n",
       "26  [vestlige, erhvervsaktive, alder, stort, under...  \n",
       "27  [sjøst, sidste, brug, lige, nu, støjbergs, slø...  \n",
       "28  [rigtig, ærgerligt, socialdemokratiet, dropper...  \n",
       "29  [stolte, kåringen, hej, randahl, ja, lille, pa...  \n",
       "30  [stort, velkommen, tilbage, folketingsgruppen,...  \n",
       "31  [nye, borgerlige, nedlægge, hver, femte, offen...  \n",
       "32  [kl, slår, gået, galt, stadig, redde, vort, la...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!python -m pip install -r requirements.txt\n",
    "from utils.initialization import *\n",
    "\n",
    "\n",
    "# med mrjob\n",
    "# names, party and twitter id\n",
    "from Data.twitter_ids import twitter_ids\n",
    "data = pd.DataFrame(columns=['name', \"party\", 'twitter_id'])\n",
    "i = 0\n",
    "for party in twitter_ids:\n",
    "    for person in twitter_ids[party]:\n",
    "        data.loc[i, :] = [person, party, twitter_ids[party][person]]\n",
    "        i += 1\n",
    "\n",
    "# tweets\n",
    "filename = \"Data/cleaned_data.csv\"\n",
    "if not os.path.exists(filename):\n",
    "    os.system(f\"python utils/clean_data_mrjob.py Data/tweets > Data/tmp_cleaned_data.txt\")\n",
    "    data_ = pd.DataFrame(columns=[\"name\", \"tweets\"])\n",
    "    with open(\"Data/tmp_cleaned_data.txt\", \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            line = eval(line.decode())\n",
    "            data_.loc[i,\"name\"] = list(line.keys())[0]\n",
    "            data_.loc[i, \"tweets\"] = list(line.values())[0]\n",
    "    data_.to_csv(filename, index = False)\n",
    "\n",
    "data_ = pd.read_csv(filename)\n",
    "data = data.merge(data_)\n",
    "data.tweets = [eval(t) for t in data.tweets]\n",
    "data[\"tokens\"] = [[w for w in word_tokenize(\" \".join(data[\"tweets\"][i])) if w.isalnum()] for i in range(len(data))]\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df = data.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>twitter_id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pia_kjarsgaard</td>\n",
       "      <td>dansk_folkeparti</td>\n",
       "      <td>1054640354690039809</td>\n",
       "      <td>[nye borgerlige nedlægge hver femte offentlige...</td>\n",
       "      <td>[nye, borgerlige, nedlægge, hver, femte, offen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soren_pape</td>\n",
       "      <td>konservative</td>\n",
       "      <td>2712091824</td>\n",
       "      <td>[tak mindst tak konstruktive input, dag god da...</td>\n",
       "      <td>[tak, mindst, tak, konstruktive, input, dag, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kim_andersen</td>\n",
       "      <td>nye_borgerlige</td>\n",
       "      <td>783935815600799744</td>\n",
       "      <td>[vestlige erhvervsaktive alder stort underskud...</td>\n",
       "      <td>[vestlige, erhvervsaktive, alder, stort, under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rasmus_jarlov</td>\n",
       "      <td>konservative</td>\n",
       "      <td>1225930531</td>\n",
       "      <td>[fuldstændig korrekt budskabet opslag sidste s...</td>\n",
       "      <td>[fuldstændig, korrekt, budskabet, opslag, sids...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pia_dyhr</td>\n",
       "      <td>sf</td>\n",
       "      <td>65025162</td>\n",
       "      <td>[stemmer nok selvom synes gør godt klaus, brug...</td>\n",
       "      <td>[stemmer, nok, selvom, synes, gør, godt, klaus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name             party           twitter_id  \\\n",
       "0  pia_kjarsgaard  dansk_folkeparti  1054640354690039809   \n",
       "1      soren_pape      konservative           2712091824   \n",
       "2    kim_andersen    nye_borgerlige   783935815600799744   \n",
       "3   rasmus_jarlov      konservative           1225930531   \n",
       "4        pia_dyhr                sf             65025162   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  [nye borgerlige nedlægge hver femte offentlige...   \n",
       "1  [tak mindst tak konstruktive input, dag god da...   \n",
       "2  [vestlige erhvervsaktive alder stort underskud...   \n",
       "3  [fuldstændig korrekt budskabet opslag sidste s...   \n",
       "4  [stemmer nok selvom synes gør godt klaus, brug...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [nye, borgerlige, nedlægge, hver, femte, offen...  \n",
       "1  [tak, mindst, tak, konstruktive, input, dag, g...  \n",
       "2  [vestlige, erhvervsaktive, alder, stort, under...  \n",
       "3  [fuldstændig, korrekt, budskabet, opslag, sids...  \n",
       "4  [stemmer, nok, selvom, synes, gør, godt, klaus...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_df.reset_index(inplace=True, drop=True)\n",
    "mini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter på at implementere solutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingle(aString, q, delimiter=' '):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - aString (str): string to split into shingles\n",
    "        - q (int)\n",
    "        - delimiter (str): string of the delimiter to consider to split the input string (default: space)\n",
    "    Return: list of unique shingles\n",
    "    \"\"\"\n",
    "    all_shingles = []\n",
    "    if delimiter != '':\n",
    "        words_list = aString.split(delimiter)\n",
    "    else:\n",
    "        words_list = aString\n",
    "    for i in range (len(words_list)-q+1):\n",
    "        all_shingles.append(delimiter.join(words_list[i:i+q]))\n",
    "    return list(set(all_shingles))\n",
    "\n",
    "    \n",
    "# Example from the Book\n",
    "# ex_string, q = test, 3\n",
    "# ex_shingles = shingle(ex_string, q, delimiter='')\n",
    "# print('Initial string:', ex_string)\n",
    "# print(f'>> Shingles with q = {q} :',ex_shingles)\n",
    "\n",
    "# Example from the HINT\n",
    "for i in range(len(mini_df)):\n",
    "    ex_string, q = ' '.join(mini_df['tokens'][i]), 2\n",
    "    ex_shingles = shingle(ex_string, q)\n",
    "    # assert len(ex_shingles) == 7\n",
    "    # add shingle to the dataframe\n",
    "    mini_df.loc[i, 'shingles'] = str(ex_shingles)\n",
    "\n",
    "    # print('\\nInitial string:', ex_string)\n",
    "    # print(f'>> Shingles with q = {q} :',ex_shingles)\n",
    "\n",
    "# ex_string, q = 'test', 2\n",
    "# ex_shingles = shingle(ex_string, q)\n",
    "# assert len(ex_shingles) == 7\n",
    "# print('\\nInitial string:', ex_string)\n",
    "# print(f'>> Shingles with q = {q} :',ex_shingles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each shingle is a list of `q` words. We can use the `hash` function to convert each shingle into a number. We can then use the `min` function to find the smallest hash value for each document. This is the signature for the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minhashing algorithm\n",
    "Now we implement the minhashing algorithm. `minhash` that takes a list of shingles and a seed for the hash function\n",
    "mapping the shingles, and outputs the minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import mmh3\n",
    "\n",
    "#hashes a list of strings\n",
    "def listhash(l,seed):\n",
    "\tval = 0\n",
    "\tfor e in l:\n",
    "\t\tval = val ^ mmh3.hash(e, seed)\n",
    "\treturn val \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash(shingles_list, seed):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - shingles_list (list of str): set of hashes\n",
    "        - seed (int): seed for listhash function\n",
    "    Return: minhash of given shingles\n",
    "    \"\"\"\n",
    "    minhash_value = None\n",
    "    for aShingle in shingles_list:\n",
    "        hashcode = listhash([aShingle], seed)\n",
    "        if minhash_value == None or hashcode < minhash_value:\n",
    "            minhash_value = hashcode\n",
    "    return minhash_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinHash of mini_df.shingles[0]: -1807661444\n"
     ]
    }
   ],
   "source": [
    "print(f'MinHash of mini_df.shingles[0]:', minhash(mini_df.shingles[3], 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash2(shingles_list, k):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - shingles_list (list of str): set of hashes\n",
    "        - k (int): seed for listhash function\n",
    "    Return: sequence of k minhashes\n",
    "    \"\"\"\n",
    "    all_minhash = []\n",
    "    for i in range(k):\n",
    "        all_minhash.append(minhash(shingles_list, i))\n",
    "    return all_minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinHash of  with k = 10:\n",
      " [-2128973781, -2079525880, -1962080891, -2099459879, -2119527857, -2122446291, -2127011794, -2093912739, -2135496994, -1918403894]\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "print(f'MinHash of  with k = {k}:\\n', minhash2(mini_df.shingles[3], k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do this for all and save the minhash value to the dataframe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dokumenter\\Dokumenter\\Git_Projects\\02807_dkpol\\kat_tester.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dokumenter/Dokumenter/Git_Projects/02807_dkpol/kat_tester.ipynb#ch0000038?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(mini_df)):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dokumenter/Dokumenter/Git_Projects/02807_dkpol/kat_tester.ipynb#ch0000038?line=1'>2</a>\u001b[0m     mini_df\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mminhash_list\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m minhash2(mini_df\u001b[39m.\u001b[39mshingles[i], \u001b[39m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bayka\\Anaconda3\\envs\\katrine_personal_env\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    715\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 716\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\bayka\\Anaconda3\\envs\\katrine_personal_env\\lib\\site-packages\\pandas\\core\\indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1642\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj[key] \u001b[39m=\u001b[39m infer_fill_value(value)\n\u001b[0;32m   1644\u001b[0m     new_indexer \u001b[39m=\u001b[39m convert_from_missing_indexer_tuple(\n\u001b[0;32m   1645\u001b[0m         indexer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39maxes\n\u001b[0;32m   1646\u001b[0m     )\n\u001b[1;32m-> 1647\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer(new_indexer, value, name)\n\u001b[0;32m   1649\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m \u001b[39m# reindex the axis\u001b[39;00m\n\u001b[0;32m   1652\u001b[0m \u001b[39m# make sure to clear the cache because we are\u001b[39;00m\n\u001b[0;32m   1653\u001b[0m \u001b[39m# just replacing the block manager here\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m \u001b[39m# so the object is the same\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bayka\\Anaconda3\\envs\\katrine_personal_env\\lib\\site-packages\\pandas\\core\\indexing.py:1688\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1687\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1688\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\bayka\\Anaconda3\\envs\\katrine_personal_env\\lib\\site-packages\\pandas\\core\\indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1738\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_integer(info_axis):\n\u001b[0;32m   1739\u001b[0m         \u001b[39m# This is a case like df.iloc[:3, [1]] = [0]\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m         \u001b[39m#  where we treat as df.iloc[:3, 1] = 0\u001b[39;00m\n\u001b[0;32m   1741\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[39m0\u001b[39m]), value[\u001b[39m0\u001b[39m])\n\u001b[1;32m-> 1743\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1744\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMust have equal len keys and value \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1745\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwhen setting with an iterable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1746\u001b[0m     )\n\u001b[0;32m   1748\u001b[0m \u001b[39melif\u001b[39;00m lplane_indexer \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mindex):\n\u001b[0;32m   1749\u001b[0m     \u001b[39m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "for i in range(len(mini_df)):\n",
    "    mini_df.loc[i, 'minhash_list'] = minhash2(mini_df.shingles[i], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>twitter_id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokens</th>\n",
       "      <th>shingles</th>\n",
       "      <th>minhash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pia_kjarsgaard</td>\n",
       "      <td>dansk_folkeparti</td>\n",
       "      <td>1054640354690039809</td>\n",
       "      <td>[nye borgerlige nedlægge hver femte offentlige...</td>\n",
       "      <td>[nye, borgerlige, nedlægge, hver, femte, offen...</td>\n",
       "      <td>['dfmedlemmer opfordrer', 'handler frihed', 's...</td>\n",
       "      <td>-1.807661e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soren_pape</td>\n",
       "      <td>konservative</td>\n",
       "      <td>2712091824</td>\n",
       "      <td>[tak mindst tak konstruktive input, dag god da...</td>\n",
       "      <td>[tak, mindst, tak, konstruktive, input, dag, g...</td>\n",
       "      <td>['samråd vej', 'lindberg danmark', 'lokale men...</td>\n",
       "      <td>-1.807661e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kim_andersen</td>\n",
       "      <td>nye_borgerlige</td>\n",
       "      <td>783935815600799744</td>\n",
       "      <td>[vestlige erhvervsaktive alder stort underskud...</td>\n",
       "      <td>[vestlige, erhvervsaktive, alder, stort, under...</td>\n",
       "      <td>['vel resten', 'kun regeringen', 'jer alligeve...</td>\n",
       "      <td>-1.807661e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rasmus_jarlov</td>\n",
       "      <td>konservative</td>\n",
       "      <td>1225930531</td>\n",
       "      <td>[fuldstændig korrekt budskabet opslag sidste s...</td>\n",
       "      <td>[fuldstændig, korrekt, budskabet, opslag, sids...</td>\n",
       "      <td>['regeringens ulovlige', 'spørge pressen', 'sk...</td>\n",
       "      <td>-1.807661e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pia_dyhr</td>\n",
       "      <td>sf</td>\n",
       "      <td>65025162</td>\n",
       "      <td>[stemmer nok selvom synes gør godt klaus, brug...</td>\n",
       "      <td>[stemmer, nok, selvom, synes, gør, godt, klaus...</td>\n",
       "      <td>['inspirerende samtale', 'stadig tid', 'sverig...</td>\n",
       "      <td>-1.807661e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name             party           twitter_id  \\\n",
       "0  pia_kjarsgaard  dansk_folkeparti  1054640354690039809   \n",
       "1      soren_pape      konservative           2712091824   \n",
       "2    kim_andersen    nye_borgerlige   783935815600799744   \n",
       "3   rasmus_jarlov      konservative           1225930531   \n",
       "4        pia_dyhr                sf             65025162   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  [nye borgerlige nedlægge hver femte offentlige...   \n",
       "1  [tak mindst tak konstruktive input, dag god da...   \n",
       "2  [vestlige erhvervsaktive alder stort underskud...   \n",
       "3  [fuldstændig korrekt budskabet opslag sidste s...   \n",
       "4  [stemmer nok selvom synes gør godt klaus, brug...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [nye, borgerlige, nedlægge, hver, femte, offen...   \n",
       "1  [tak, mindst, tak, konstruktive, input, dag, g...   \n",
       "2  [vestlige, erhvervsaktive, alder, stort, under...   \n",
       "3  [fuldstændig, korrekt, budskabet, opslag, sids...   \n",
       "4  [stemmer, nok, selvom, synes, gør, godt, klaus...   \n",
       "\n",
       "                                            shingles       minhash  \n",
       "0  ['dfmedlemmer opfordrer', 'handler frihed', 's... -1.807661e+09  \n",
       "1  ['samråd vej', 'lindberg danmark', 'lokale men... -1.807661e+09  \n",
       "2  ['vel resten', 'kun regeringen', 'jer alligeve... -1.807661e+09  \n",
       "3  ['regeringens ulovlige', 'spørge pressen', 'sk... -1.807661e+09  \n",
       "4  ['inspirerende samtale', 'stadig tid', 'sverig... -1.807661e+09  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signature(dict_docs, q = q, num_hashes = k):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - dict_docs (dict of str:str): dictionary of {title:document}\n",
    "        - q (int)\n",
    "        - num_hashes (int)\n",
    "    Return: dictionary consisting of document id’s as keys and signatures as values\n",
    "    \"\"\"\n",
    "    dict_signatures = {}\n",
    "    total_texts = len(list(dict_docs.keys()))\n",
    "    counter = 1\n",
    "    for key,text in dict_docs.items():\n",
    "        print(f'{counter}/{total_texts} - {key} - Processing...')\n",
    "        doc_shingles = shingle(text, q)\n",
    "        minhash_values = minhash2(doc_shingles, num_hashes)\n",
    "        dict_signatures[key] = minhash_values\n",
    "        counter += 1\n",
    "    return dict_signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-1cbe2894-0702-49cd-ac63-e2293e52639d",
    "deepnote_cell_height": 205,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# converting a string of text into a vector. Using teh transformer BERT model\n",
    "\n",
    "# Step one: Use BERT to convert our text into a vector\n",
    "# Step two:Get the cosine similarity (the cosine of the angle between the two vectors) \n",
    "    # of a fixed twitter profiles (vector) and all the other ones\n",
    "# Step three: Pick the twitter profiles (vectors) with the largest cosine similarity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-b088bcc1-8283-4b2b-89d6-3a5b154765cc",
    "deepnote_cell_height": 357,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8b4274d1ac4e4c891a7560580f8563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step one\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "text_data = giant_df.CT\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "embeddings = model.encode(text_data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-a587b35f-3d49-4bdf-8710-1bb9eb18f7a1",
    "deepnote_cell_height": 79,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "X = np.array(giant_df.CT)\n",
    "# cos_sim_data = pd.DataFrame(cosine_similarity(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-22a0109a-dd72-4afc-ad56-803d99685b08",
    "deepnote_cell_height": 552,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hands-on-content-based-recommender-system-using-python-1d643bf314e4\n",
    "\n",
    "def give_recommendations(index,print_recommendation = False,print_recommendation_plots= False,print_parties =False):\n",
    "  index_recomm =cos_sim_data.loc[index].sort_values(ascending=False).index.tolist()[1:10]\n",
    "  party_recomm =  giant_df['Party'].loc[index_recomm].values\n",
    "  result = {'PArty':party_recomm,'Index':index_recomm}\n",
    "  if print_recommendation==True:\n",
    "    print('The watched movie is this one: %s \\n'%(giant_df['Person'].loc[index]))\n",
    "    k=1\n",
    "    for movie in party_recomm:\n",
    "      print('The number %i recommended movie is this one: %s \\n'%(k,movie))\n",
    "  if print_recommendation_plots==True:\n",
    "    print('The plot of the watched movie is this one:\\n %s \\n'%(giant_df['CT'].loc[index]))\n",
    "    k=1\n",
    "    for q in range(len(party_recomm)):\n",
    "      plot_q = giant_df['Overview'].loc[index_recomm[q]]\n",
    "      print('The plot of the number %i recommended movie is this one:\\n %s \\n'%(k,plot_q))\n",
    "      k=k+1\n",
    "  if print_parties==True:\n",
    "    print('The party of the twitter profile is this one:\\n %s \\n'%(giant_df['Party'].loc[index]))\n",
    "    k=1\n",
    "    for q in range(len(party_recomm)):\n",
    "      plot_q = giant_df['Party'].loc[index_recomm[q]]\n",
    "      print('The plot of the number %i recommended party is this one:\\n %s \\n'%(k,plot_q))\n",
    "      k=k+1\n",
    "  return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-b58d9dda-32f7-4637-bf99-235e0441d757",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# check if 'sundhedsminister' is in the list\n",
    "\n",
    "if 'sundhedsministeren' in doc[0]:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-303c0e1b-a8d2-4a6d-8c4f-f394ba24a7e4",
    "deepnote_cell_height": 61,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=30797f9c-952e-45b4-98d4-31c9ac73ae78' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "1584dd31-1e1c-4b66-9d76-016448129ed3",
  "kernelspec": {
   "display_name": "Python 3.8.13 ('katrine_personal_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23b47e8941e9532a227126a88d0aed60e854f3b3d5618484cace29efe7d4fdfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
