{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "b9d670f9-28bf-4981-8f9e-cf22056d423f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "522fcc3f",
    "execution_start": 1669796212454,
    "execution_millis": 3522,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 544.1875
   },
   "source": "from IPython.display import display\nimport pandas as pd\nimport requests\nimport re\nfrom urllib.request import urlopen\nimport csv\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n#from fa2 import ForceAtlas2\nfrom scipy import stats\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nimport io\nfrom tqdm import tqdm\nfrom heapq import nlargest \nimport seaborn as sns\nimport simplemma\n\nsns.set()",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simplemma'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mheapq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nlargest \n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msimplemma\u001b[39;00m\n\u001b[1;32m     21\u001b[0m sns\u001b[38;5;241m.\u001b[39mset()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simplemma'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00001-85b91341-db30-4a23-b5f7-7a9378c6a973",
    "deepnote_cell_type": "code"
   },
   "source": "%load_ext autoreload\n%autoreload 2\n!python -m pip install -r requirements.txt\nfrom utils.initialization import *\n\n\n# med mrjob\n# names, party and twitter id\nfrom Data.twitter_ids import twitter_ids\ndata = pd.DataFrame(columns=['name', \"party\", 'twitter_id'])\ni = 0\nfor party in twitter_ids:\n    for person in twitter_ids[party]:\n        data.loc[i, :] = [person, party, twitter_ids[party][person]]\n        i += 1\n\n# tweets\nfilename = \"Data/cleaned_data.csv\"\nif not os.path.exists(filename):\n    os.system(f\"python utils/clean_data_mrjob.py Data/tweets > Data/tmp_cleaned_data.txt\")\n    data_ = pd.DataFrame(columns=[\"name\", \"tweets\"])\n    with open(\"Data/tmp_cleaned_data.txt\", \"rb\") as f:\n        lines = f.readlines()\n        for i, line in enumerate(lines):\n            line = eval(line.decode())\n            data_.loc[i,\"name\"] = list(line.keys())[0]\n            data_.loc[i, \"tweets\"] = list(line.values())[0]\n    data_.to_csv(filename, index = False)\n\ndata_ = pd.read_csv(filename)\ndata = data.merge(data_)\ndata.tweets = [eval(t) for t in data.tweets]\ndata[\"tokens\"] = [[w for w in word_tokenize(\" \".join(data[\"tweets\"][i])) if w.isalnum()] for i in range(len(data))]\nimport simplemma #use simplemma instead of nltk.WordNetLemmatizer()          ### vi har addet denne linje\ndata[\"tokens\"] = [[simplemma.lemmatize(w, lang='da') for w in data[\"tokens\"][i]] for i in range(len(data))] ### vi har addet denne linje\n\n# only include unique words\ndata['tokens'] = data['tokens'].apply(lambda x: list(set(x)))\n\ndata\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nRequirement already satisfied: spacy in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 1)) (3.4.3)\nRequirement already satisfied: mrjob==0.7.4 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 2)) (0.7.4)\nRequirement already satisfied: simplemma in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 3)) (0.9.0)\nRequirement already satisfied: tqdm in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 4)) (4.64.0)\nRequirement already satisfied: nltk in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 5)) (3.7)\nRequirement already satisfied: wordcloud in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 6)) (1.8.2.2)\nRequirement already satisfied: sklearn in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from -r requirements.txt (line 7)) (0.0.post1)\nRequirement already satisfied: PyYAML>=3.10 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from mrjob==0.7.4->-r requirements.txt (line 2)) (6.0)\nRequirement already satisfied: click in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (8.1.3)\nRequirement already satisfied: regex>=2021.8.3 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (2022.10.31)\nRequirement already satisfied: joblib in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (1.1.0)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (0.10.1)\nRequirement already satisfied: pathy>=0.3.5 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (0.9.0)\nRequirement already satisfied: setuptools in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (61.2.0)\nRequirement already satisfied: numpy>=1.15.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (1.22.4)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (2.0.7)\nRequirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (0.7.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (3.3.0)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (1.0.3)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (3.0.8)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (1.10.2)\nRequirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (8.1.5)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (2.4.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (1.0.9)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (2.0.8)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (2.28.0)\nRequirement already satisfied: jinja2 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: packaging>=20.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from spacy->-r requirements.txt (line 1)) (3.0.10)\nRequirement already satisfied: colorama in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from tqdm->-r requirements.txt (line 4)) (0.4.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from packaging>=20.0->spacy->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from pathy>=0.3.5->spacy->-r requirements.txt (line 1)) (5.2.1)\nRequirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->-r requirements.txt (line 1)) (4.2.0)\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 1)) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 1)) (2022.5.18.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 1)) (1.26.9)\nRequirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 1)) (2.0.12)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 1)) (0.7.9)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 1)) (0.0.3)\nRequirement already satisfied: matplotlib in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from wordcloud->-r requirements.txt (line 6)) (3.5.2)\nRequirement already satisfied: pillow in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from wordcloud->-r requirements.txt (line 6)) (9.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from jinja2->spacy->-r requirements.txt (line 1)) (2.1.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (1.4.3)\nRequirement already satisfied: python-dateutil>=2.7 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (4.33.3)\nRequirement already satisfied: six>=1.5 in c:\\users\\bayka\\anaconda3\\envs\\katrine_personal_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud->-r requirements.txt (line 6)) (1.16.0)\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "WARNING: You are using pip version 21.0.1; however, version 22.3.1 is available.\nYou should consider upgrading via the 'c:\\Users\\bayka\\Anaconda3\\envs\\katrine_personal_env\\python.exe -m pip install --upgrade pip' command.\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>party</th>\n      <th>twitter_id</th>\n      <th>tweets</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magnus_heunicke</td>\n      <td>socialdemokratiet</td>\n      <td>22695562</td>\n      <td>[afsætter året styrke hjælpen børn pårørende a...</td>\n      <td>[british, landsplan, baltisk, vist, missed, kv...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>nicolai_wammen</td>\n      <td>socialdemokratiet</td>\n      <td>2803948786</td>\n      <td>[dage siden sagde nyt ejendomsvurderingssystem...</td>\n      <td>[bent, mn, baltisk, vist, træ, splitte, elysee...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mattias_tesfaye</td>\n      <td>socialdemokratiet</td>\n      <td>546254893</td>\n      <td>[this is literally the same logic many th c am...</td>\n      <td>[bent, snitte, vist, maradona, udlændingenævne...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>jakob_ellemann</td>\n      <td>venstre</td>\n      <td>155584627</td>\n      <td>[tide få fleksibel genåbning vores børn ældre ...</td>\n      <td>[stén, vrede, ministertid, vist, anne, varig, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>soren_gade</td>\n      <td>venstre</td>\n      <td>975064362359623680</td>\n      <td>[kære marianne synes burde læse lovforslaget i...</td>\n      <td>[tusindvis, mirakelkur, antisemitisme, betting...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>sophie_lohde</td>\n      <td>venstre</td>\n      <td>44611200</td>\n      <td>[flertallet veto dermed røde partier stort set...</td>\n      <td>[skræmmeka, des, vist, anmeldelse, underernæri...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>lars_lokke</td>\n      <td>moderaterne</td>\n      <td>26201346</td>\n      <td>[mon ikke sjov form argumentation mangler lidt...</td>\n      <td>[udgiftslov, bent, des, vist, folketingsspørgs...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>jacob_mark</td>\n      <td>sf</td>\n      <td>2373406198</td>\n      <td>[slår fast syvtommersøm kom så godt igennem fo...</td>\n      <td>[landsplan, snitte, vist, olieboring, dragsted...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>pia_dyhr</td>\n      <td>sf</td>\n      <td>65025162</td>\n      <td>[stemmer nok selvom synes gør godt klaus, brug...</td>\n      <td>[baltisk, vist, stefan, træ, hand, anne, samir...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>kirsten_andersen</td>\n      <td>sf</td>\n      <td>235646319</td>\n      <td>[arbejde få medarbejdere ser virkeligheden sun...</td>\n      <td>[bent, landsplan, julegudstjenester, vist, træ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>dennis_flydtkjær</td>\n      <td>danmarksdemokraterne</td>\n      <td>531595033</td>\n      <td>[vel blot gældende forlig k i åbner det, europ...</td>\n      <td>[bent, gratisydelse, lovgrundlag, vist, dreami...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>peter_skaarup</td>\n      <td>danmarksdemokraterne</td>\n      <td>3144074691</td>\n      <td>[justitsminister åbenbart svare på ogeller sik...</td>\n      <td>[bent, vrede, lovgrundlag, vist, anmeldelse, s...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>soren_espersen</td>\n      <td>danmarksdemokraterne</td>\n      <td>2444718215</td>\n      <td>[godt arbejde, det undre allermest forbindelse...</td>\n      <td>[bent, vrede, southern, british, baltisk, des,...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>alex_vanopslagh</td>\n      <td>liberal_alliance</td>\n      <td>1531564633</td>\n      <td>[tror mest mennesket sætter gud prøve, mette f...</td>\n      <td>[des, landsplan, vist, dalgaard, anmeldelse, s...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ole_olesen</td>\n      <td>liberal_alliance</td>\n      <td>2222188479</td>\n      <td>[findes ingen talemåde slå stålet så andet ste...</td>\n      <td>[partigokkeriet, bent, podcastplatform, vist, ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>soren_pape</td>\n      <td>konservative</td>\n      <td>2712091824</td>\n      <td>[tak mindst tak konstruktive input, dag god da...</td>\n      <td>[bent, vrede, ministertid, vist, anmeldelse, v...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>mette_abildgaard</td>\n      <td>konservative</td>\n      <td>37877392</td>\n      <td>[men kæmpe indsatsen lavere fjernvarmepriser n...</td>\n      <td>[bent, snitte, vist, klimaudsp, anne, træ, luk...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>rasmus_jarlov</td>\n      <td>konservative</td>\n      <td>1225930531</td>\n      <td>[fuldstændig korrekt budskabet opslag sidste s...</td>\n      <td>[vist, læserbrev, varig, splitte, dråbe, kg, p...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>pelle_dragsted</td>\n      <td>enhedslisten</td>\n      <td>119879630</td>\n      <td>[syriske mariam udvises gift jan venter barn l...</td>\n      <td>[vrede, affaldsforbrænding, emerita, monetaris...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>mai_villadsen</td>\n      <td>enhedslisten</td>\n      <td>4724782641</td>\n      <td>[husk sexisme seksuel chikane magt arbejde gør...</td>\n      <td>[affaldsforbrænding, sommershoppingtur, landsp...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>rosa_lund</td>\n      <td>enhedslisten</td>\n      <td>736979161</td>\n      <td>[russiske flygtninge større chance få asyl ukr...</td>\n      <td>[bent, dirt, landsplan, anmeldelse, anne, indf...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>martin_lidegaard</td>\n      <td>radikale</td>\n      <td>1070745218</td>\n      <td>[ja dokumentere fem år arbejdet indenfor felt ...</td>\n      <td>[bent, british, vrede, frema, olieudvinding, v...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>samira_nawa</td>\n      <td>radikale</td>\n      <td>92107029</td>\n      <td>[andet vigtigt klimarådet konkluderer dag lang...</td>\n      <td>[bent, dialogforums, snitte, vist, læserbrev, ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>katrine_robsoe</td>\n      <td>radikale</td>\n      <td>2491403660</td>\n      <td>[tak samarbejdet, godt dkpol, vores uddannelse...</td>\n      <td>[vist, uddannelseskvaliteten, anne, varig, sam...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>pernille_vermund</td>\n      <td>nye_borgerlige</td>\n      <td>24687777</td>\n      <td>[lars løkke varslede åbningstale flere udlændi...</td>\n      <td>[udgiftslov, intolerant, fnaftalen, vist, anme...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>lars_mathiesen</td>\n      <td>nye_borgerlige</td>\n      <td>980721900</td>\n      <td>[siger del svagt enhedslisten reelt står rød b...</td>\n      <td>[bent, arguing, vrede, des, vist, varig, sugar...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>kim_andersen</td>\n      <td>nye_borgerlige</td>\n      <td>783935815600799744</td>\n      <td>[vestlige erhvervsaktive alder stort underskud...</td>\n      <td>[baltisk, vist, træ, statministeren, ligning, ...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>franciska_rosenkilde</td>\n      <td>alternativet</td>\n      <td>777113466205274112</td>\n      <td>[sjøst sidste brug lige nu støjbergs sløje kul...</td>\n      <td>[splitte, flygtningelejr, biodiversitetskrisen...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>christina_olumeko</td>\n      <td>alternativet</td>\n      <td>1324801335372488707</td>\n      <td>[rigtig ærgerligt socialdemokratiet dropper ar...</td>\n      <td>[vist, ut, bæredygtighed, valuta, parre, stærk...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>torsten_gejl</td>\n      <td>alternativet</td>\n      <td>2806864609</td>\n      <td>[stolte kåringen, hej randahl, ja lille parti ...</td>\n      <td>[vist, træ, muliggøre, rovdrift, tange, flygtn...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>morten_messerschmidt</td>\n      <td>dansk_folkeparti</td>\n      <td>509288627</td>\n      <td>[stort velkommen tilbage folketingsgruppen ige...</td>\n      <td>[baltisk, vist, stemnej, træ, splitte, treated...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>pia_kjarsgaard</td>\n      <td>dansk_folkeparti</td>\n      <td>1054640354690039809</td>\n      <td>[nye borgerlige nedlægge hver femte offentlige...</td>\n      <td>[lovgrundlag, des, vist, stefan, stemnej, anne...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>peter_kofod</td>\n      <td>dansk_folkeparti</td>\n      <td>1613378210</td>\n      <td>[kl slår gået galt stadig redde vort land kræv...</td>\n      <td>[vrede, vist, stemnej, splitte, plenarsalen, i...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    name                 party           twitter_id  \\\n0        magnus_heunicke     socialdemokratiet             22695562   \n1         nicolai_wammen     socialdemokratiet           2803948786   \n2        mattias_tesfaye     socialdemokratiet            546254893   \n3         jakob_ellemann               venstre            155584627   \n4             soren_gade               venstre   975064362359623680   \n5           sophie_lohde               venstre             44611200   \n6             lars_lokke           moderaterne             26201346   \n7             jacob_mark                    sf           2373406198   \n8               pia_dyhr                    sf             65025162   \n9       kirsten_andersen                    sf            235646319   \n10      dennis_flydtkjær  danmarksdemokraterne            531595033   \n11         peter_skaarup  danmarksdemokraterne           3144074691   \n12        soren_espersen  danmarksdemokraterne           2444718215   \n13       alex_vanopslagh      liberal_alliance           1531564633   \n14            ole_olesen      liberal_alliance           2222188479   \n15            soren_pape          konservative           2712091824   \n16      mette_abildgaard          konservative             37877392   \n17         rasmus_jarlov          konservative           1225930531   \n18        pelle_dragsted          enhedslisten            119879630   \n19         mai_villadsen          enhedslisten           4724782641   \n20             rosa_lund          enhedslisten            736979161   \n21      martin_lidegaard              radikale           1070745218   \n22           samira_nawa              radikale             92107029   \n23        katrine_robsoe              radikale           2491403660   \n24      pernille_vermund        nye_borgerlige             24687777   \n25        lars_mathiesen        nye_borgerlige            980721900   \n26          kim_andersen        nye_borgerlige   783935815600799744   \n27  franciska_rosenkilde          alternativet   777113466205274112   \n28     christina_olumeko          alternativet  1324801335372488707   \n29          torsten_gejl          alternativet           2806864609   \n30  morten_messerschmidt      dansk_folkeparti            509288627   \n31        pia_kjarsgaard      dansk_folkeparti  1054640354690039809   \n32           peter_kofod      dansk_folkeparti           1613378210   \n\n                                               tweets  \\\n0   [afsætter året styrke hjælpen børn pårørende a...   \n1   [dage siden sagde nyt ejendomsvurderingssystem...   \n2   [this is literally the same logic many th c am...   \n3   [tide få fleksibel genåbning vores børn ældre ...   \n4   [kære marianne synes burde læse lovforslaget i...   \n5   [flertallet veto dermed røde partier stort set...   \n6   [mon ikke sjov form argumentation mangler lidt...   \n7   [slår fast syvtommersøm kom så godt igennem fo...   \n8   [stemmer nok selvom synes gør godt klaus, brug...   \n9   [arbejde få medarbejdere ser virkeligheden sun...   \n10  [vel blot gældende forlig k i åbner det, europ...   \n11  [justitsminister åbenbart svare på ogeller sik...   \n12  [godt arbejde, det undre allermest forbindelse...   \n13  [tror mest mennesket sætter gud prøve, mette f...   \n14  [findes ingen talemåde slå stålet så andet ste...   \n15  [tak mindst tak konstruktive input, dag god da...   \n16  [men kæmpe indsatsen lavere fjernvarmepriser n...   \n17  [fuldstændig korrekt budskabet opslag sidste s...   \n18  [syriske mariam udvises gift jan venter barn l...   \n19  [husk sexisme seksuel chikane magt arbejde gør...   \n20  [russiske flygtninge større chance få asyl ukr...   \n21  [ja dokumentere fem år arbejdet indenfor felt ...   \n22  [andet vigtigt klimarådet konkluderer dag lang...   \n23  [tak samarbejdet, godt dkpol, vores uddannelse...   \n24  [lars løkke varslede åbningstale flere udlændi...   \n25  [siger del svagt enhedslisten reelt står rød b...   \n26  [vestlige erhvervsaktive alder stort underskud...   \n27  [sjøst sidste brug lige nu støjbergs sløje kul...   \n28  [rigtig ærgerligt socialdemokratiet dropper ar...   \n29  [stolte kåringen, hej randahl, ja lille parti ...   \n30  [stort velkommen tilbage folketingsgruppen ige...   \n31  [nye borgerlige nedlægge hver femte offentlige...   \n32  [kl slår gået galt stadig redde vort land kræv...   \n\n                                               tokens  \n0   [british, landsplan, baltisk, vist, missed, kv...  \n1   [bent, mn, baltisk, vist, træ, splitte, elysee...  \n2   [bent, snitte, vist, maradona, udlændingenævne...  \n3   [stén, vrede, ministertid, vist, anne, varig, ...  \n4   [tusindvis, mirakelkur, antisemitisme, betting...  \n5   [skræmmeka, des, vist, anmeldelse, underernæri...  \n6   [udgiftslov, bent, des, vist, folketingsspørgs...  \n7   [landsplan, snitte, vist, olieboring, dragsted...  \n8   [baltisk, vist, stefan, træ, hand, anne, samir...  \n9   [bent, landsplan, julegudstjenester, vist, træ...  \n10  [bent, gratisydelse, lovgrundlag, vist, dreami...  \n11  [bent, vrede, lovgrundlag, vist, anmeldelse, s...  \n12  [bent, vrede, southern, british, baltisk, des,...  \n13  [des, landsplan, vist, dalgaard, anmeldelse, s...  \n14  [partigokkeriet, bent, podcastplatform, vist, ...  \n15  [bent, vrede, ministertid, vist, anmeldelse, v...  \n16  [bent, snitte, vist, klimaudsp, anne, træ, luk...  \n17  [vist, læserbrev, varig, splitte, dråbe, kg, p...  \n18  [vrede, affaldsforbrænding, emerita, monetaris...  \n19  [affaldsforbrænding, sommershoppingtur, landsp...  \n20  [bent, dirt, landsplan, anmeldelse, anne, indf...  \n21  [bent, british, vrede, frema, olieudvinding, v...  \n22  [bent, dialogforums, snitte, vist, læserbrev, ...  \n23  [vist, uddannelseskvaliteten, anne, varig, sam...  \n24  [udgiftslov, intolerant, fnaftalen, vist, anme...  \n25  [bent, arguing, vrede, des, vist, varig, sugar...  \n26  [baltisk, vist, træ, statministeren, ligning, ...  \n27  [splitte, flygtningelejr, biodiversitetskrisen...  \n28  [vist, ut, bæredygtighed, valuta, parre, stærk...  \n29  [vist, træ, muliggøre, rovdrift, tange, flygtn...  \n30  [baltisk, vist, stemnej, træ, splitte, treated...  \n31  [lovgrundlag, des, vist, stefan, stemnej, anne...  \n32  [vrede, vist, stemnej, splitte, plenarsalen, i...  "
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-531ccc76-d38f-4cec-ad7d-cdf3ed081388",
    "deepnote_cell_type": "code"
   },
   "source": "mini_df = data #data.sample(5, random_state=42)\n# add party to the name\nmini_df['name'] = mini_df['name'] + ' ' + mini_df['party']",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Starter på at implementere solutions ",
   "metadata": {
    "cell_id": "00003-5845434a-0597-42f5-bbad-b9055f8e737f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Shingles",
   "metadata": {
    "cell_id": "00004-13481c40-f476-471e-b531-242d30a351f3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00005-b0db9691-1c11-4565-98ac-bdd117cb9eb9",
    "deepnote_cell_type": "code"
   },
   "source": "def shingle(aString, q, delimiter=' '):\n    \"\"\"\n    Input:\n        - aString (str): string to split into shingles\n        - q (int)\n        - delimiter (str): string of the delimiter to consider to split the input string (default: space)\n    Return: list of unique shingles\n    \"\"\"\n    all_shingles = []\n    if delimiter != '':\n        words_list = aString.split(delimiter)\n    else:\n        words_list = aString\n    for i in range (len(words_list)-q+1):\n        all_shingles.append(delimiter.join(words_list[i:i+q]))\n    return list(set(all_shingles))\n\n    \n# Example from the Book\n# ex_string, q = test, 3\n# ex_shingles = shingle(ex_string, q, delimiter='')\n# print('Initial string:', ex_string)\n# print(f'>> Shingles with q = {q} :',ex_shingles)\n\n# Example from the HINT\nfor i in range(len(mini_df)):\n    ex_string, q = ' '.join(mini_df['tokens'][i]), 2\n    ex_shingles = shingle(ex_string, q)\n    # assert len(ex_shingles) == 7\n    # add shingle to the dataframe\n    mini_df.loc[i, 'shingles'] = str(ex_shingles)\n\n    # print('\\nInitial string:', ex_string)\n    # print(f'>> Shingles with q = {q} :',ex_shingles)\n\n# ex_string, q = 'test', 2\n# ex_shingles = shingle(ex_string, q)\n# assert len(ex_shingles) == 7\n# print('\\nInitial string:', ex_string)\n# print(f'>> Shingles with q = {q} :',ex_shingles)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Now each shingle is a list of `q` words. We can use the `hash` function to convert each shingle into a number. We can then use the `min` function to find the smallest hash value for each document. This is the signature for the document.",
   "metadata": {
    "cell_id": "00006-ae9d4ef5-c039-4417-bce3-beb6529cf817",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Lav TF-IDF til en kolonne i dataframen",
   "metadata": {
    "cell_id": "00007-869dcb2e-7800-42e9-8262-f0340916c757",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00008-da5aef24-8402-4f51-9def-6796c0bea183",
    "deepnote_cell_type": "code"
   },
   "source": "# According to the book (9.2.2) we can get the n most important (highest tfidf score) words PER document and treat them as a set\n# (unlike cosine similarity that treats the vectors with 0s and 1s for each time a word appears in both documents)\n#https://www.analyticsvidhya.com/blog/2021/12/how-to-extract-key-phrases-using-tfidf-with-python/\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(max_features=700, stop_words='english')\nvectors = vectorizer.fit_transform(mini_df.tokens.apply(lambda x: \" \".join(x)))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00009-69443c5c-0216-4dce-b381-6752fa3c1bdb",
    "deepnote_cell_type": "code"
   },
   "source": "vectors",
   "outputs": [
    {
     "data": {
      "text/plain": "<33x700 sparse matrix of type '<class 'numpy.float64'>'\n\twith 21305 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00010-4947dd6d-2abc-4cf4-b22c-016d65ac0e77",
    "deepnote_cell_type": "code"
   },
   "source": "dict_of_tokens={i[1]:i[0] for i in vectorizer.vocabulary_.items()}",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00011-7fda5ff1-05ca-4c1d-8005-e264d9657be7",
    "deepnote_cell_type": "code"
   },
   "source": "tfidf_vectors = []  # all deoc vectors by tfidf\nfor row in vectors:\n  tfidf_vectors.append({dict_of_tokens[column]:value for (column,value) in zip(row.indices,row.data)})\nprint(\"number of documents\",len(tfidf_vectors), \"the dictionary of document 1\", len(tfidf_vectors[3].keys()))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "number of documents 33 the dictionary of document 1 677\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00012-acc91ebe-010d-40d4-9a68-11484763c568",
    "deepnote_cell_type": "code"
   },
   "source": "mini_df['TFIDF_Words'] = [list(tfidf_vectors[i].keys()) for i in range(len(mini_df))]\n# mini_df['TFIDF_Words'].iloc[0]",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Minhashing algorithm\nNow we implement the minhashing algorithm. `minhash` that takes a list of shingles and a seed for the hash function\nmapping the shingles, and outputs the minhash",
   "metadata": {
    "cell_id": "00013-5b4bf67f-8263-40e7-b667-fc0a635313a6",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00014-b5cd19af-94ad-4316-aead-bb14037e7e03",
    "deepnote_cell_type": "code"
   },
   "source": "import sys\nimport os\nimport mmh3\n\n#hashes a list of strings\ndef listhash(l,seed):\n\tval = 0\n\tfor e in l:\n\t\tval = val ^ mmh3.hash(e, seed)\n\treturn val \n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "#### TODO her tager vi istedet for shingles_list lister af tf-idfs",
   "metadata": {
    "cell_id": "00015-61f3a868-83c1-4024-8c4d-4469a8a9741c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00016-e45ac1bf-e34d-4319-b541-9e0c4fe591fe",
    "deepnote_cell_type": "code"
   },
   "source": "def minhash(shingles_list, seed):\n    \"\"\"\n    Input:\n        - shingles_list (list of str): set of hashes\n        - seed (int): seed for listhash function\n    Return: minhash of given shingles\n    \"\"\"\n    minhash_value = None\n    for aShingle in shingles_list:\n        hashcode = listhash([aShingle], seed)\n        if minhash_value == None or hashcode < minhash_value:\n            minhash_value = hashcode\n    return minhash_value",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00017-02b11f3d-156b-49b4-9be2-f0b7ecbcd6db",
    "deepnote_cell_type": "code"
   },
   "source": "# print(f'MinHash of mini_df.shingles[0]:', minhash(mini_df.shingles[4], 42))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00018-39488054-3bc4-4339-a07e-74d055a8baf5",
    "deepnote_cell_type": "code"
   },
   "source": "def minhash2(shingles_list, k):\n    \"\"\"\n    Input:\n        - shingles_list (list of str): set of hashes\n        - k (int): seed for listhash function\n    Return: sequence of k minhashes\n    \"\"\"\n    all_minhash = []\n    for i in range(k):\n        all_minhash.append(minhash(shingles_list, i))\n    return all_minhash",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00019-6147bb8a-37de-4434-89bf-79f8f2313557",
    "deepnote_cell_type": "code"
   },
   "source": "# k=42\n# print(f'MinHash of  with k = {k}:\\n', minhash2(mini_df.shingles[3], k))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Do this for all and save the minhash value to the dataframe \n\n",
   "metadata": {
    "cell_id": "00020-d9ea4716-7262-4da7-aab8-4130a6f7945e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00021-0c1d9297-78e6-4ff4-9c7f-7a67f5e00ca3",
    "deepnote_cell_type": "code"
   },
   "source": "# for i in range(len(mini_df)):\n#     mini_df.loc[i, 'minhash_tokens'] = minhash(mini_df.tokens[i], 10)\n\n# for i in range(len(mini_df)):\n#     mini_df.loc[i, 'minhas_tf'] = minhash(mini_df.TFIDF_Words[i], 10)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Signatures",
   "metadata": {
    "cell_id": "00022-d0f06f38-d432-429d-9e77-e5ee741bd6e6",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00023-9aeb1889-2046-420b-9f83-afa685bba3bf",
    "deepnote_cell_type": "code"
   },
   "source": "k=10\n# def signature(dict_docs, q = q, num_hashes = k):\ndef signature(dict_docs, num_hashes = k):\n\n    \"\"\"\n    Input:\n        - dict_docs (dict of str:str): dictionary of {title:document}\n        - q (int)\n        - num_hashes (int)\n    Return: dictionary consisting of document id’s as keys and signatures as values\n    \"\"\"\n    dict_signatures = {}\n    total_texts = len(list(dict_docs.keys()))\n    counter = 1\n    for key,text in dict_docs.items():\n        print(f'{counter}/{total_texts} - {key} - Processing...')\n        # doc_shingles = shingle(text, q)\n        doc_shingles = mini_df.tokens[counter-1]\n        # doc_shingles = mini_df.TFIDF_Words[counter-1]\n        minhash_values = minhash2(doc_shingles, num_hashes)\n        dict_signatures[key] = minhash_values\n        counter += 1\n    return dict_signatures",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00024-5ae6e019-2a28-40d0-b3e4-1147acc6456c",
    "deepnote_cell_type": "code"
   },
   "source": "# dict_docs is a dictionary of {name:TFIDF_Words}\n# dict_docs = {i:j for i,j in zip(mini_df['name'],mini_df['TFIDF_Words'])}\n# dict_docs = {i:j for i,j in zip(mini_df['name'],mini_df['tokens'])}\ndict_docs = {i:j for i,j in zip(mini_df['party'],mini_df['tokens'])}\n\n\n\n# signature_dict = signature(dict_docs, q = 2, num_hashes = 100)\nsignature_dict = signature(dict_docs, num_hashes = 200)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1/12 - socialdemokratiet - Processing...\n2/12 - venstre - Processing...\n3/12 - moderaterne - Processing...\n4/12 - sf - Processing...\n5/12 - danmarksdemokraterne - Processing...\n6/12 - liberal_alliance - Processing...\n7/12 - konservative - Processing...\n8/12 - enhedslisten - Processing...\n9/12 - radikale - Processing...\n10/12 - nye_borgerlige - Processing...\n11/12 - alternativet - Processing...\n12/12 - dansk_folkeparti - Processing...\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Jaccard similarity",
   "metadata": {
    "cell_id": "00025-cad83143-c452-4fed-ab4d-7579db704cdf",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00026-56aa6d1d-1984-47bb-914e-07bb48925a5a",
    "deepnote_cell_type": "code"
   },
   "source": "# def jaccard_similarity(x,y):\n#   \"\"\" returns the jaccard similarity between two lists \"\"\"\n#   intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n#   union_cardinality = len(set.union(*[set(x), set(y)]))\n#   return intersection_cardinality/float(union_cardinality)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00027-29eb41ad-e630-4d55-9bb5-6d5cc32c9cee",
    "deepnote_cell_type": "code"
   },
   "source": "def jaccard(name1, name2, signature_dict):\n    \"\"\"\n    Input:\n        - name1 (str): key of the first document S\n        - name2 (str): key of the second document T\n        - signatures_dict (dict of str:list): dictionary of signatures\n    Return: Jaccard similarity between S and T\n    \"\"\"\n    signatures_doc1 = np.array(signature_dict[name1])\n    signatures_doc2 = np.array(signature_dict[name2])\n    # return np.sum(signatures_doc1 == signatures_doc2) #/ len(signatures_doc1)\n    return len(np.intersect1d(signatures_doc1, signatures_doc2))/len(np.union1d(signatures_doc1, signatures_doc2))#, np.setdiff1d(signatures_doc1, signatures_doc2)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00028-fa7a2b87-2506-4d17-875c-d31b64a8b1ca",
    "deepnote_cell_type": "code"
   },
   "source": "# signature_dict['soren_pape']\n# signature_dict",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00029-4f6c30e3-0681-488c-8a43-be780d0b7799",
    "deepnote_cell_type": "code"
   },
   "source": "\nfirst_doc_key = mini_df.party[1]#list(docs.keys())[0]\nsecond_doc_key = mini_df.party[2]#list(docs.keys())[1]\nprint(f'Jaccard similarity between {first_doc_key} and {second_doc_key}:', jaccard(first_doc_key, second_doc_key, signature_dict))#dict_signatures_docs))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Jaccard similarity between socialdemokratiet and socialdemokratiet: 1.0\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# similarity",
   "metadata": {
    "cell_id": "00030-2bac33ee-5696-4374-abef-2da1cb488e22",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00031-2fe39877-761f-446d-946b-25388da1cd2c",
    "deepnote_cell_type": "code"
   },
   "source": "def similar(signatures_dict, jaccard_threshold=0.05):\n    \"\"\"\n    Input:\n        - signatures_dict (dict of str:list): dictionary of signatures\n        - jaccard_threshold (float): lower bound for Jaccard similarity score to consider\n            two documents as similar\n    Return: dictionary of similar items\n    \"\"\"\n    list_keys = list(signatures_dict.keys())\n    similar_items = {}\n    for i in range (len(list_keys)-1):\n        for j in range (i+1, len(list_keys)):\n            similarity_score = jaccard(list_keys[i], list_keys[j], signatures_dict)\n            if similarity_score >= jaccard_threshold:\n                similar_items[(list_keys[i], list_keys[j])] = similarity_score\n    return similar_items",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00032-2b72b426-100c-4587-9f69-5167c7a15f6d",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00033-d9c0836f-689f-42d4-841c-e04966a51365",
    "deepnote_cell_type": "code"
   },
   "source": "found_similar_items = similar(signature_dict)\n# print('Found similar items:\\n', found_similar_items)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00034-4e1729e8-19cf-4940-8e5e-212a578de9bd",
    "deepnote_cell_type": "code"
   },
   "source": "# get the most similar items\nmost_similar_items = sorted(found_similar_items.items(), key=lambda x: x[1], reverse=True)\n# print('Most similar items:\\n', most_similar_items[0:20])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00035-acf9b79a-9e0e-46ac-aa34-57109ad4a9ff",
    "deepnote_cell_type": "code"
   },
   "source": "# for every person, return the 3 people most similar to him/her\ndef most_similar_persons(similar_items, num_similar_persons=3):\n    \"\"\"\n    Input:\n        - similar_items (dict of tuple:str): dictionary of similar items\n        - num_similar_persons (int): number of similar persons to return\n    Return: dictionary of most similar persons\n    \"\"\"\n    most_similar_persons = {}\n    for key,value in similar_items.items():\n        if key[0] not in most_similar_persons:\n            most_similar_persons[key[0]] = [(key[1], value)]\n        else:\n            most_similar_persons[key[0]].append((key[1], value))\n        if key[1] not in most_similar_persons:\n            most_similar_persons[key[1]] = [(key[0], value)]\n        else:\n            most_similar_persons[key[1]].append((key[0], value))\n    for key,value in most_similar_persons.items():\n        most_similar_persons[key] = sorted(value, key=lambda x: x[1], reverse=True)[:num_similar_persons]\n    return most_similar_persons\n\nmost_similar_persons_res = most_similar_persons(found_similar_items)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00036-8c60392d-6b8f-4d73-85f5-18b772ff13b8",
    "deepnote_cell_type": "code"
   },
   "source": "# convert most_similar_persons_res to a datamframe for easier visualization\nmost_similar_persons_df = pd.DataFrame.from_dict(most_similar_persons_res, orient='index')\nmost_similar_persons_df.columns = ['Most similar person 1', 'Most similar person 2', 'Most similar person 3']\nmost_similar_persons_df",
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Most similar person 1</th>\n      <th>Most similar person 2</th>\n      <th>Most similar person 3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>socialdemokratiet</th>\n      <td>(nye_borgerlige, 0.1396011396011396)</td>\n      <td>(sf, 0.12359550561797752)</td>\n      <td>(enhedslisten, 0.12359550561797752)</td>\n    </tr>\n    <tr>\n      <th>venstre</th>\n      <td>(alternativet, 0.14613180515759314)</td>\n      <td>(sf, 0.1267605633802817)</td>\n      <td>(radikale, 0.11731843575418995)</td>\n    </tr>\n    <tr>\n      <th>moderaterne</th>\n      <td>(dansk_folkeparti, 0.13314447592067988)</td>\n      <td>(sf, 0.12994350282485875)</td>\n      <td>(liberal_alliance, 0.1267605633802817)</td>\n    </tr>\n    <tr>\n      <th>sf</th>\n      <td>(liberal_alliance, 0.19402985074626866)</td>\n      <td>(konservative, 0.17994100294985252)</td>\n      <td>(radikale, 0.17647058823529413)</td>\n    </tr>\n    <tr>\n      <th>liberal_alliance</th>\n      <td>(sf, 0.19402985074626866)</td>\n      <td>(radikale, 0.1695906432748538)</td>\n      <td>(nye_borgerlige, 0.16279069767441862)</td>\n    </tr>\n    <tr>\n      <th>konservative</th>\n      <td>(sf, 0.17994100294985252)</td>\n      <td>(dansk_folkeparti, 0.15606936416184972)</td>\n      <td>(nye_borgerlige, 0.14942528735632185)</td>\n    </tr>\n    <tr>\n      <th>enhedslisten</th>\n      <td>(nye_borgerlige, 0.17647058823529413)</td>\n      <td>(sf, 0.15942028985507245)</td>\n      <td>(liberal_alliance, 0.14942528735632185)</td>\n    </tr>\n    <tr>\n      <th>radikale</th>\n      <td>(sf, 0.17647058823529413)</td>\n      <td>(nye_borgerlige, 0.17647058823529413)</td>\n      <td>(liberal_alliance, 0.1695906432748538)</td>\n    </tr>\n    <tr>\n      <th>nye_borgerlige</th>\n      <td>(enhedslisten, 0.17647058823529413)</td>\n      <td>(radikale, 0.17647058823529413)</td>\n      <td>(sf, 0.16279069767441862)</td>\n    </tr>\n    <tr>\n      <th>alternativet</th>\n      <td>(sf, 0.15273775216138327)</td>\n      <td>(venstre, 0.14613180515759314)</td>\n      <td>(liberal_alliance, 0.1396011396011396)</td>\n    </tr>\n    <tr>\n      <th>dansk_folkeparti</th>\n      <td>(sf, 0.15942028985507245)</td>\n      <td>(radikale, 0.15942028985507245)</td>\n      <td>(konservative, 0.15606936416184972)</td>\n    </tr>\n    <tr>\n      <th>danmarksdemokraterne</th>\n      <td>(nye_borgerlige, 0.07816711590296496)</td>\n      <td>(enhedslisten, 0.07526881720430108)</td>\n      <td>(radikale, 0.06666666666666667)</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                        Most similar person 1  \\\nsocialdemokratiet        (nye_borgerlige, 0.1396011396011396)   \nvenstre                   (alternativet, 0.14613180515759314)   \nmoderaterne           (dansk_folkeparti, 0.13314447592067988)   \nsf                    (liberal_alliance, 0.19402985074626866)   \nliberal_alliance                    (sf, 0.19402985074626866)   \nkonservative                        (sf, 0.17994100294985252)   \nenhedslisten            (nye_borgerlige, 0.17647058823529413)   \nradikale                            (sf, 0.17647058823529413)   \nnye_borgerlige            (enhedslisten, 0.17647058823529413)   \nalternativet                        (sf, 0.15273775216138327)   \ndansk_folkeparti                    (sf, 0.15942028985507245)   \ndanmarksdemokraterne    (nye_borgerlige, 0.07816711590296496)   \n\n                                        Most similar person 2  \\\nsocialdemokratiet                   (sf, 0.12359550561797752)   \nvenstre                              (sf, 0.1267605633802817)   \nmoderaterne                         (sf, 0.12994350282485875)   \nsf                        (konservative, 0.17994100294985252)   \nliberal_alliance               (radikale, 0.1695906432748538)   \nkonservative          (dansk_folkeparti, 0.15606936416184972)   \nenhedslisten                        (sf, 0.15942028985507245)   \nradikale                (nye_borgerlige, 0.17647058823529413)   \nnye_borgerlige                (radikale, 0.17647058823529413)   \nalternativet                   (venstre, 0.14613180515759314)   \ndansk_folkeparti              (radikale, 0.15942028985507245)   \ndanmarksdemokraterne      (enhedslisten, 0.07526881720430108)   \n\n                                        Most similar person 3  \nsocialdemokratiet         (enhedslisten, 0.12359550561797752)  \nvenstre                       (radikale, 0.11731843575418995)  \nmoderaterne            (liberal_alliance, 0.1267605633802817)  \nsf                            (radikale, 0.17647058823529413)  \nliberal_alliance        (nye_borgerlige, 0.16279069767441862)  \nkonservative            (nye_borgerlige, 0.14942528735632185)  \nenhedslisten          (liberal_alliance, 0.14942528735632185)  \nradikale               (liberal_alliance, 0.1695906432748538)  \nnye_borgerlige                      (sf, 0.16279069767441862)  \nalternativet           (liberal_alliance, 0.1396011396011396)  \ndansk_folkeparti          (konservative, 0.15606936416184972)  \ndanmarksdemokraterne          (radikale, 0.06666666666666667)  "
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00037-8b26b03c-55d6-43f0-ab4a-badf8141b57c",
    "deepnote_cell_type": "code"
   },
   "source": "\n# make a group of names for each party (for visualization)\ndef make_party_groups(df, party_column_name):\n    \"\"\"\n    Input:\n        - df (pd.DataFrame): dataframe with the party column\n        - party_column_name (str): name of the party column\n    Return: dictionary of party groups\n    \"\"\"\n    party_groups = {}\n    for party in df[party_column_name].unique():\n        party_groups[party] = list(df[df[party_column_name] == party].name)\n    return party_groups\n\nparty_groups = make_party_groups(mini_df, 'party')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00038-e39ad270-7fc6-45e1-8c12-a6840fa9edb2",
    "deepnote_cell_type": "code"
   },
   "source": "# # look at the party of the most similar items\n# similar_items_names = [i for i in found_similar_items.keys()]\n# for i in range(len(similar_items_names)):\n#     print(mini_df[mini_df.name.isin(similar_items_names[i])].party)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# LSH",
   "metadata": {
    "cell_id": "00039-fbb6962f-64ea-4307-b564-86817dbaa678",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00040-dd545e9f-4152-4ce3-8952-e531a2478e45",
    "deepnote_cell_type": "code"
   },
   "source": "b,r = 20, 5\n# assert k == b*r\n\ndef lsh(signatures_dict, jaccard_threshold=0.05, seed=10):\n    lsh_dict = {}\n    for key, values in signatures_dict.items():\n        blocks = np.split(np.array(values), b)\n        blocks_hash_values = []\n        for aBlock in blocks:\n            blocks_hash_values.append(mmh3.hash(aBlock, seed))\n        lsh_dict[key] = blocks_hash_values\n    list_keys = list(lsh_dict.keys())\n    similar_items = {}\n    for i in range (len(list_keys)-1):\n        for j in range (i+1, len(list_keys)):\n            common_values = np.intersect1d(lsh_dict[list_keys[i]], lsh_dict[list_keys[j]])\n            if len(common_values) > 0:\n                # we found a candidate\n                similarity_score = jaccard(list_keys[i], list_keys[j], signatures_dict)\n                if similarity_score >= jaccard_threshold:\n                    similar_items[(list_keys[i], list_keys[j])] = similarity_score\n    return similar_items\nfound_similar_items_with_lsh = lsh(signature_dict)\nprint('Found similar items with LSH:\\n', found_similar_items_with_lsh)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found similar items with LSH:\n {}\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00041-036e678a-3b49-4ab8-8786-9c53cc956c14",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00008-1cbe2894-0702-49cd-ac63-e2293e52639d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 205
   },
   "source": "# converting a string of text into a vector. Using teh transformer BERT model\n\n# Step one: Use BERT to convert our text into a vector\n# Step two:Get the cosine similarity (the cosine of the angle between the two vectors) \n    # of a fixed twitter profiles (vector) and all the other ones\n# Step three: Pick the twitter profiles (vectors) with the largest cosine similarity.\n\n\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00011-22a0109a-dd72-4afc-ad56-803d99685b08",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 552
   },
   "source": "# https://towardsdatascience.com/hands-on-content-based-recommender-system-using-python-1d643bf314e4\n\ndef give_recommendations(index,print_recommendation = False,print_recommendation_plots= False,print_parties =False):\n  index_recomm =cos_sim_data.loc[index].sort_values(ascending=False).index.tolist()[1:10]\n  party_recomm =  giant_df['Party'].loc[index_recomm].values\n  result = {'PArty':party_recomm,'Index':index_recomm}\n  if print_recommendation==True:\n    print('The watched movie is this one: %s \\n'%(giant_df['Person'].loc[index]))\n    k=1\n    for movie in party_recomm:\n      print('The number %i recommended movie is this one: %s \\n'%(k,movie))\n  if print_recommendation_plots==True:\n    print('The plot of the watched movie is this one:\\n %s \\n'%(giant_df['CT'].loc[index]))\n    k=1\n    for q in range(len(party_recomm)):\n      plot_q = giant_df['Overview'].loc[index_recomm[q]]\n      print('The plot of the number %i recommended movie is this one:\\n %s \\n'%(k,plot_q))\n      k=k+1\n  if print_parties==True:\n    print('The party of the twitter profile is this one:\\n %s \\n'%(giant_df['Party'].loc[index]))\n    k=1\n    for q in range(len(party_recomm)):\n      plot_q = giant_df['Party'].loc[index_recomm[q]]\n      print('The plot of the number %i recommended party is this one:\\n %s \\n'%(k,plot_q))\n      k=k+1\n  return result\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00013-303c0e1b-a8d2-4a6d-8c4f-f394ba24a7e4",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 61
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=30797f9c-952e-45b4-98d4-31c9ac73ae78' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "1584dd31-1e1c-4b66-9d76-016448129ed3",
  "kernelspec": {
   "display_name": "Python 3.8.13 ('katrine_personal_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23b47e8941e9532a227126a88d0aed60e854f3b3d5618484cace29efe7d4fdfe"
   }
  }
 }
}